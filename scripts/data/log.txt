[2025-07-03 13:34:39,324 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpyyogm_cc/test.c -o /tmp/tmpyyogm_cc/test.o
[2025-07-03 13:34:39,336 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpyyogm_cc/test.o -laio -o /tmp/tmpyyogm_cc/a.out
[2025-07-03 13:34:39,437 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpd0lad6md/test.c -o /tmp/tmpd0lad6md/test.o
[2025-07-03 13:34:39,450 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpd0lad6md/test.o -laio -o /tmp/tmpd0lad6md/a.out
[2025-07-03 13:34:39,856 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp1py9rd66/test.c -o /tmp/tmp1py9rd66/test.o
[2025-07-03 13:34:39,868 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp1py9rd66/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmp1py9rd66/a.out
[2025-07-03 13:34:39,964 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpmeuuxmrx/test.c -o /tmp/tmpmeuuxmrx/test.o
[2025-07-03 13:34:39,977 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpmeuuxmrx/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpmeuuxmrx/a.out
[2025-07-03 13:37:37,932 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp4j4n6fjd/test.c -o /tmp/tmp4j4n6fjd/test.o
[2025-07-03 13:37:37,945 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp4j4n6fjd/test.o -laio -o /tmp/tmp4j4n6fjd/a.out
[2025-07-03 13:37:37,967 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpy07hui3c/test.c -o /tmp/tmpy07hui3c/test.o
[2025-07-03 13:37:37,979 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpy07hui3c/test.o -laio -o /tmp/tmpy07hui3c/a.out
[2025-07-03 13:37:38,459 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmple5yt8v9/test.c -o /tmp/tmple5yt8v9/test.o
[2025-07-03 13:37:38,471 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmple5yt8v9/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmple5yt8v9/a.out
[2025-07-03 13:37:38,527 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpm4tyjji8/test.c -o /tmp/tmpm4tyjji8/test.o
[2025-07-03 13:37:38,540 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpm4tyjji8/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpm4tyjji8/a.out
[2025-07-03 13:48:01,292 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpunvw2uci/test.c -o /tmp/tmpunvw2uci/test.o
[2025-07-03 13:48:01,304 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpunvw2uci/test.o -laio -o /tmp/tmpunvw2uci/a.out
[2025-07-03 13:48:01,329 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp6ud1l341/test.c -o /tmp/tmp6ud1l341/test.o
[2025-07-03 13:48:01,342 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp6ud1l341/test.o -laio -o /tmp/tmp6ud1l341/a.out
[2025-07-03 13:48:01,812 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp0ydhd4po/test.c -o /tmp/tmp0ydhd4po/test.o
[2025-07-03 13:48:01,824 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp0ydhd4po/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmp0ydhd4po/a.out
[2025-07-03 13:48:01,854 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpt7s_f8_t/test.c -o /tmp/tmpt7s_f8_t/test.o
[2025-07-03 13:48:01,866 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpt7s_f8_t/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpt7s_f8_t/a.out
[2025-07-03 13:48:03,156 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1347.45/runs/Jul03_13-48-01_elotfi,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1347.45,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1347.45,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-03 13:48:22,579 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-03 13:48:22,644 INFO] Vocab size: 250002
[2025-07-03 13:48:23,211 ERROR] Failed to load JSON from file '/home/ubuntu/projects/RetData/data/synret_50k.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Column(/pos) changed from string to array in row 23
[2025-07-03 13:48:23,415 ERROR] Failed to load JSON from file '/home/ubuntu/projects/RetData/data/synret_50k.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Column(/pos) changed from string to array in row 23
[2025-07-03 14:34:08,170 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpfctyr6fy/test.c -o /tmp/tmpfctyr6fy/test.o
[2025-07-03 14:34:08,170 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp80x7_vxe/test.c -o /tmp/tmp80x7_vxe/test.o
[2025-07-03 14:34:08,183 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpfctyr6fy/test.o -laio -o /tmp/tmpfctyr6fy/a.out
[2025-07-03 14:34:08,183 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp80x7_vxe/test.o -laio -o /tmp/tmp80x7_vxe/a.out
[2025-07-03 14:34:08,697 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpfijhcy2y/test.c -o /tmp/tmpfijhcy2y/test.o
[2025-07-03 14:34:08,710 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpfijhcy2y/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpfijhcy2y/a.out
[2025-07-03 14:34:08,733 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpea3qz8ml/test.c -o /tmp/tmpea3qz8ml/test.o
[2025-07-03 14:34:08,745 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpea3qz8ml/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpea3qz8ml/a.out
[2025-07-03 14:34:09,502 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1433.51/runs/Jul03_14-34-08_elotfi,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1433.51,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1433.51,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../../data/synret_50kk.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-03 14:34:11,093 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-03 14:34:11,134 INFO] Vocab size: 250002
[2025-07-03 14:36:29,075 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpfcbjlgca/test.c -o /tmp/tmpfcbjlgca/test.o
[2025-07-03 14:36:29,087 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpfcbjlgca/test.o -laio -o /tmp/tmpfcbjlgca/a.out
[2025-07-03 14:36:29,147 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp3v8l_kqo/test.c -o /tmp/tmp3v8l_kqo/test.o
[2025-07-03 14:36:29,160 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp3v8l_kqo/test.o -laio -o /tmp/tmp3v8l_kqo/a.out
[2025-07-03 14:36:29,631 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmprpp1jfx0/test.c -o /tmp/tmprpp1jfx0/test.o
[2025-07-03 14:36:29,644 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmprpp1jfx0/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmprpp1jfx0/a.out
[2025-07-03 14:36:29,688 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpbke6burk/test.c -o /tmp/tmpbke6burk/test.o
[2025-07-03 14:36:29,700 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpbke6burk/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpbke6burk/a.out
[2025-07-03 14:36:30,569 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1436.13/runs/Jul03_14-36-29_elotfi,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1436.13,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1436.13,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../../data/synret_50kk.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-03 14:36:33,018 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-03 14:36:33,163 INFO] Vocab size: 250002
[2025-07-03 14:36:33,617 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.'}.
[2025-07-03 14:36:33,621 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.'}.
[2025-07-03 14:36:33,621 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen'}.
[2025-07-03 14:39:41,451 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpvc7p6f50/test.c -o /tmp/tmpvc7p6f50/test.o
[2025-07-03 14:39:41,452 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpbcl016pw/test.c -o /tmp/tmpbcl016pw/test.o
[2025-07-03 14:39:41,463 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpvc7p6f50/test.o -laio -o /tmp/tmpvc7p6f50/a.out
[2025-07-03 14:39:41,464 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpbcl016pw/test.o -laio -o /tmp/tmpbcl016pw/a.out
[2025-07-03 14:39:41,989 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpj1j73ceo/test.c -o /tmp/tmpj1j73ceo/test.o
[2025-07-03 14:39:42,000 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpj1j73ceo/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpj1j73ceo/a.out
[2025-07-03 14:39:42,014 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp7fywuykg/test.c -o /tmp/tmp7fywuykg/test.o
[2025-07-03 14:39:42,026 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp7fywuykg/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmp7fywuykg/a.out
[2025-07-03 14:39:43,124 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1439.24/runs/Jul03_14-39-41_elotfi,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1439.24,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-03-1439.24,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../../data/synret_50kk.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-03 14:39:44,719 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-03 14:39:44,771 INFO] Vocab size: 250002
[2025-07-03 14:39:45,127 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.'}.
[2025-07-03 14:39:45,128 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.'}.
[2025-07-03 14:39:45,128 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen'}.
[2025-07-04 08:37:12,959 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpcdb_faer/test.c -o /tmp/tmpcdb_faer/test.o
[2025-07-04 08:37:12,961 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpbba832pu/test.c -o /tmp/tmpbba832pu/test.o
[2025-07-04 08:37:12,972 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpcdb_faer/test.o -laio -o /tmp/tmpcdb_faer/a.out
[2025-07-04 08:37:12,973 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpbba832pu/test.o -laio -o /tmp/tmpbba832pu/a.out
[2025-07-04 08:37:13,487 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmpm_iera54/test.c -o /tmp/tmpm_iera54/test.o
[2025-07-04 08:37:13,499 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmpm_iera54/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmpm_iera54/a.out
[2025-07-04 08:37:13,523 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -DNDEBUG -D_FORTIFY_SOURCE=2 -O2 -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -fPIC -march=nocona -mtune=haswell -ftree-vectorize -fPIC -fstack-protector-strong -fno-plt -O2 -ffunction-sections -pipe -isystem /home/ubuntu/miniconda3/envs/hf/include -I/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/include -c /tmp/tmp32zmaedu/test.c -o /tmp/tmp32zmaedu/test.o
[2025-07-04 08:37:13,535 INFO] /home/ubuntu/miniconda3/envs/hf/bin/x86_64-conda-linux-gnu-cc -Wl,-O2 -Wl,--sort-common -Wl,--as-needed -Wl,-z,relro -Wl,-z,now -Wl,--disable-new-dtags -Wl,--gc-sections -Wl,-rpath,/home/ubuntu/miniconda3/envs/hf/lib -Wl,-rpath-link,/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib -L/home/ubuntu/miniconda3/envs/hf/targets/x86_64-linux/lib/stubs /tmp/tmp32zmaedu/test.o -L/home/ubuntu/miniconda3/envs/hf -L/home/ubuntu/miniconda3/envs/hf/lib64 -lcufile -o /tmp/tmp32zmaedu/a.out
[2025-07-04 08:37:14,972 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-04-0836.56/runs/Jul04_08-37-12_elotfi,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-04-0836.56,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/home/ubuntu/projects/RetData/finetune/checkpoint/biencoder_syn_2025-07-04-0836.56,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-04 08:37:16,677 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-04 08:37:16,716 INFO] Vocab size: 250002
[2025-07-04 08:37:17,446 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-04 08:37:17,446 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-04 08:37:17,446 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 11:28:59,365 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmpb1mjmy7e/test.c -o /tmp/tmpb1mjmy7e/test.o
[2025-07-07 11:28:59,388 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmpb1mjmy7e/test.o -laio -o /tmp/tmpb1mjmy7e/a.out
[2025-07-07 11:28:59,424 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmp2zmiqt5j/test.c -o /tmp/tmp2zmiqt5j/test.o
[2025-07-07 11:28:59,446 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmp2zmiqt5j/test.o -laio -o /tmp/tmp2zmiqt5j/a.out
[2025-07-07 11:29:00,574 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1128.46/runs/Jul07_11-28-59_687641d39a4d,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=50,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1128.46,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1128.46,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-07 11:29:14,827 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-07 11:29:14,913 INFO] Vocab size: 250002
[2025-07-07 11:29:15,480 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 11:29:15,481 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-07 11:29:15,484 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 11:29:15,597 WARNING] Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2025-07-07 16:32:41,295 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmp70gxknga/test.c -o /tmp/tmp70gxknga/test.o
[2025-07-07 16:32:41,312 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmp70gxknga/test.o -laio -o /tmp/tmp70gxknga/a.out
[2025-07-07 16:32:42,250 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1632.23/runs/Jul07_16-32-41_e1c4797a5253,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1632.23,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1632.23,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-07 16:32:51,158 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-07 16:32:51,261 INFO] Vocab size: 250002
[2025-07-07 16:32:51,825 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:32:51,825 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-07 16:32:51,826 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:36:32,337 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmpog1vug18/test.c -o /tmp/tmpog1vug18/test.o
[2025-07-07 16:36:32,356 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmpog1vug18/test.o -laio -o /tmp/tmpog1vug18/a.out
[2025-07-07 16:36:33,642 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1636.16/runs/Jul07_16-36-32_e1c4797a5253,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1636.16,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1636.16,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-07 16:36:35,391 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-07 16:36:35,503 INFO] Vocab size: 250002
[2025-07-07 16:36:35,919 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:36:35,919 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-07 16:36:35,919 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:37:44,413 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmpr5giiwsd/test.c -o /tmp/tmpr5giiwsd/test.o
[2025-07-07 16:37:44,430 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmpr5giiwsd/test.o -laio -o /tmp/tmpr5giiwsd/a.out
[2025-07-07 16:37:45,387 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1637.29/runs/Jul07_16-37-44_e1c4797a5253,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1637.29,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1637.29,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-07 16:37:47,020 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-07 16:37:47,084 INFO] Vocab size: 250002
[2025-07-07 16:37:47,494 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:37:47,494 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-07 16:37:47,494 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:41:20,886 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmp_vzxt7ki/test.c -o /tmp/tmp_vzxt7ki/test.o
[2025-07-07 16:41:20,905 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmp_vzxt7ki/test.o -laio -o /tmp/tmp_vzxt7ki/a.out
[2025-07-07 16:41:21,910 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1641.06/runs/Jul07_16-41-20_e1c4797a5253,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1641.06,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1641.06,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-07 16:41:23,619 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-07 16:41:23,690 INFO] Vocab size: 250002
[2025-07-07 16:41:24,115 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:41:24,115 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-07 16:41:24,115 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:47:56,249 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmppcvatfu0/test.c -o /tmp/tmppcvatfu0/test.o
[2025-07-07 16:47:56,268 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmppcvatfu0/test.o -laio -o /tmp/tmppcvatfu0/a.out
[2025-07-07 16:47:57,655 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1647.41/runs/Jul07_16-47-56_e1c4797a5253,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1647.41,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1647.41,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-07 16:47:59,333 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-07 16:47:59,394 INFO] Vocab size: 250002
[2025-07-07 16:47:59,808 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:47:59,809 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-07 16:47:59,809 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:50:44,580 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmpr7grv3wi/test.c -o /tmp/tmpr7grv3wi/test.o
[2025-07-07 16:50:44,599 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmpr7grv3wi/test.o -laio -o /tmp/tmpr7grv3wi/a.out
[2025-07-07 16:50:45,786 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=../data,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=None,
eval_strategy=IntervalStrategy.EPOCH,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=2e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1650.29/runs/Jul07_16-50-44_e1c4797a5253,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1650.29,
overwrite_output_dir=True,
p_max_len=450,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=16,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
ray_scope=last,
remove_unused_columns=False,
report_to=[],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=/root/SynRet/checkpoint/biencoder_syn_2025-07-07-1650.29,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=SaveStrategy.EPOCH,
save_total_limit=2,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=../data/synret_50k.jsonl,
train_n_passages=2,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=1000,
weight_decay=0.0,
)
[2025-07-07 16:50:47,509 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-07 16:50:47,571 INFO] Vocab size: 250002
[2025-07-07 16:50:47,990 INFO] Sample 28883 of the training set: {'task_type': 'll', 'task_desc': 'Given a document that supports a debatable argument, find documents that contain opposite arguments.', 'q': "De impact van smartphones op de sociale interactie van jongeren wordt vaak als negatief beschreven. Er wordt gesuggereerd dat voortdurende smartphonegebruik leidt tot verminderd face-to-face contact, isolatie en een afname van communicatieve vaardigheden. Veel ouders en opvoeders maken zich zorgen dat jongeren meer tijd doorbrengen achter schermen dan in persoonlijke interacties, wat kan resulteren in een eenzijdige ontwikkeling van sociale competenties. Onderzoekers wijzen erop dat frequente meldingen via sociale media en ononderbroken toegang tot entertainment en games een afleidende factor vormen die de kwaliteit van echte relaties ondermijnt. Daarnaast wordt er gedacht dat overmatig gebruik van gadgets bij jongeren kan leiden tot verslaving, met negatieve gevolgen voor hun geestelijke gezondheid. Er wordt daarom gepleit voor strengere maatregelen en meer bewustwordingsprogramma's om jongeren te stimuleren fysieke maatschappelijke interacties te ervaren en de balans tussen online en offline leven te herstellen.", 'pos': "In de afgelopen jaren zijn smartphones uitgegroeid tot onmisbare apparaten die de manier waarop jongeren communiceren en informatie delen hebben veranderd. Hoewel er zorgen zijn over de mogelijke negatieve effecten van overmatig gebruik, tonen recente studies aan dat smartphones ook voordelen bieden voor sociale verbindingen. Jongeren gebruiken apps zoals WhatsApp, Instagram en TikTok om contact te houden met vrienden, nieuwe mensen te ontmoeten en deel uit te maken van online gemeenschappen. Deze digitale interacties kunnen zelfs leiden tot het versterken van sociale banden, het bieden van steun in moeilijke tijden en het bevorderen van inclusiviteit. Bovendien stelt de draagbare technologie jongeren in staat om snel informatie te verkrijgen, creatief te zijn en vaardigheden te ontwikkelen die essentieel zijn in de moderne samenleving. Onderwijsprogramma's integreren technologie op een wijze die samenwerking en communicatie bevordert, waardoor smartphones niet alleen hulpmiddelen voor entertainment zijn, maar ook instruments voor sociale en persoonlijke ontwikkeling.", 'neg': 'Hoewel gadgets zoals smartphones populair zijn onder jongeren, werpen sommige critici vraagtekens op bij de effectiviteit van technologische hulpmiddelen in educatie. Zij beweren dat de constante afleiding en de invasieve aard van notificaties kunnen leiden tot lagere concentratie en productiviteit in klaslokalen. Bovendien constateert men dat niet alle digitale platforms bedrijvig en bovendien schadelijk kunnen zijn, vooral als ze worden gebruikt zonder toezicht. Het is daarom belangrijk om beperkingen te overwegen en richtlijnen te ontwikkelen voor verantwoord gebruik, zodat de negatieve elementen niet de overhand krijgen. In scholen worden daarom vaak beleidsregels ingevoerd die het gebruik van smartphones beperken tijdens lestijden, met het doel leerlingen te helpen zich meer te richten op face-to-face interacties en minder op digitale afleiding. Hoewel technologie zeker voordelen biedt, blijft het essentieel om de juiste balans te vinden en de negatieve invloeden zoveel mogelijk te mitigeren.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:50:47,990 INFO] Sample 7657 of the training set: {'task_type': 'sts', 'task_desc': '', 'q': 'Om een perfecte tomatensaus te maken, kook je verse tomaten met knoflook en kruiden gedurende 30 minuten.', 'pos': 'Voor een heerlijke tomatensaus kook je verse tomaten samen met knoflook en basilicum ongeveer een halfuur.', 'neg': 'Je kunt verse tomaten gebruiken om een simpele saus te bereiden door ze te koken met wat kruiden.', 'scores': {'pos': 0.9, 'neg': 0.7}}.
[2025-07-07 16:50:47,990 INFO] Sample 490 of the training set: {'task_type': 'ls', 'task_desc': 'Identifying the intent or scenario of a user utterance, input, query or command.', 'q': 'In de context van industrile vloeistofsystemen is het van cruciaal belang om mechanische componenten te selecteren die niet alleen bestand zijn tegen de variabele druk en temperaturen binnen een proceslijn, maar ook compatibel zijn met de chemische eigenschappen van het vervoerde medium. Het bepalen van de juiste afdichtingen en lagers draagt aanzienlijk bij aan het minimaliseren van mechanische slijtage en het voorkomen van lekkages die kunnen leiden tot productieonderbrekingen of veiligheidsincidenten. Bovendien vereist de integratie van regelkleppen en pompstations in deze systemen een grondige analyse van de doorstroomsnelheden en het cavitatiepotentieel, waarbij dynamische simulaties vaak worden ingezet om optimale prestaties te garanderen. Het combineren van duurzame materialen met geavanceerde monitoringtechnieken resulteert in een efficinte fluid handling die voldoet aan industrile normen en milieuvoorschriften.', 'pos': 'Vloeistofhantering in industrile toepassingen', 'neg': 'Procesautomatisering en controlesystemen', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-07 16:50:52,333 INFO] {'loss': 0.4096, 'grad_norm': 20.83108139038086, 'learning_rate': 6.666666666666668e-06, 'epoch': 0.006397952655150352}
[2025-07-07 16:50:52,361 INFO] step: 10, mrr: 89.49, Acc@1: 79.55
[2025-07-07 16:50:53,467 INFO] {'loss': 0.3967, 'grad_norm': 12.310632705688477, 'learning_rate': 8.673533304426543e-06, 'epoch': 0.012795905310300703}
[2025-07-07 16:50:53,493 INFO] step: 20, mrr: 90.33, Acc@1: 81.25
[2025-07-07 16:50:54,555 INFO] {'loss': 0.3244, 'grad_norm': 13.722285270690918, 'learning_rate': 9.847475031464418e-06, 'epoch': 0.019193857965451054}
[2025-07-07 16:50:54,583 INFO] step: 30, mrr: 90.93, Acc@1: 82.46
[2025-07-07 16:50:55,642 INFO] {'loss': 0.3261, 'grad_norm': 14.12922477722168, 'learning_rate': 1.0680399942186417e-05, 'epoch': 0.025591810620601407}
[2025-07-07 16:50:55,668 INFO] step: 40, mrr: 91.39, Acc@1: 83.38
[2025-07-07 16:50:56,761 INFO] {'loss': 0.365, 'grad_norm': 14.065678596496582, 'learning_rate': 1.1326466695573459e-05, 'epoch': 0.03198976327575176}
[2025-07-07 16:50:56,793 INFO] step: 50, mrr: 91.3, Acc@1: 83.09
[2025-07-07 16:50:57,931 INFO] {'loss': 0.3135, 'grad_norm': 13.006048202514648, 'learning_rate': 1.1854341669224292e-05, 'epoch': 0.03838771593090211}
[2025-07-07 16:50:57,961 INFO] step: 60, mrr: 91.34, Acc@1: 83.09
[2025-07-07 16:50:59,123 INFO] {'loss': 0.3448, 'grad_norm': 16.813955307006836, 'learning_rate': 1.2300653600095047e-05, 'epoch': 0.044785668586052464}
[2025-07-07 16:50:59,154 INFO] step: 70, mrr: 91.77, Acc@1: 83.89
[2025-07-07 16:51:00,318 INFO] {'loss': 0.2544, 'grad_norm': 12.29713249206543, 'learning_rate': 1.2687266579946291e-05, 'epoch': 0.05118362124120281}
[2025-07-07 16:51:00,352 INFO] step: 80, mrr: 92.13, Acc@1: 84.65
[2025-07-07 16:51:01,488 INFO] {'loss': 0.295, 'grad_norm': 9.978156089782715, 'learning_rate': 1.3028283396262167e-05, 'epoch': 0.05758157389635317}
[2025-07-07 16:51:01,516 INFO] step: 90, mrr: 92.41, Acc@1: 85.16
[2025-07-07 16:51:02,578 INFO] {'loss': 0.2366, 'grad_norm': 7.377335071563721, 'learning_rate': 1.3333333333333337e-05, 'epoch': 0.06397952655150352}
[2025-07-07 16:51:02,602 INFO] step: 100, mrr: 92.57, Acc@1: 85.46
[2025-07-07 16:51:03,754 INFO] {'loss': 0.2583, 'grad_norm': 14.759119987487793, 'learning_rate': 1.3609284567721503e-05, 'epoch': 0.07037747920665387}
[2025-07-07 16:51:03,784 INFO] step: 110, mrr: 92.79, Acc@1: 85.87
[2025-07-07 16:51:04,853 INFO] {'loss': 0.2674, 'grad_norm': 27.156782150268555, 'learning_rate': 1.3861208306984167e-05, 'epoch': 0.07677543186180422}
[2025-07-07 16:51:04,880 INFO] step: 120, mrr: 93.03, Acc@1: 86.31
[2025-07-07 16:51:06,018 INFO] {'loss': 0.2693, 'grad_norm': 14.709671020507812, 'learning_rate': 1.409295568204558e-05, 'epoch': 0.08317338451695458}
[2025-07-07 16:51:06,052 INFO] step: 130, mrr: 93.01, Acc@1: 86.26
[2025-07-07 16:51:07,189 INFO] {'loss': 0.2286, 'grad_norm': 17.64199447631836, 'learning_rate': 1.4307520237854922e-05, 'epoch': 0.08957133717210493}
[2025-07-07 16:51:07,223 INFO] step: 140, mrr: 93.13, Acc@1: 86.48
[2025-07-07 16:51:08,337 INFO] {'loss': 0.2266, 'grad_norm': 10.80226993560791, 'learning_rate': 1.4507275060371209e-05, 'epoch': 0.09596928982725528}
[2025-07-07 16:51:08,371 INFO] step: 150, mrr: 93.27, Acc@1: 86.75
[2025-07-07 16:51:09,484 INFO] {'loss': 0.2395, 'grad_norm': 11.228506088256836, 'learning_rate': 1.4694133217706166e-05, 'epoch': 0.10236724248240563}
[2025-07-07 16:51:09,510 INFO] step: 160, mrr: 93.28, Acc@1: 86.8
[2025-07-07 16:51:10,615 INFO] {'loss': 0.2812, 'grad_norm': 16.119287490844727, 'learning_rate': 1.4869659475855163e-05, 'epoch': 0.10876519513755598}
[2025-07-07 16:51:10,646 INFO] step: 170, mrr: 93.29, Acc@1: 86.84
[2025-07-07 16:51:11,769 INFO] {'loss': 0.1613, 'grad_norm': 10.973191261291504, 'learning_rate': 1.5035150034022042e-05, 'epoch': 0.11516314779270634}
[2025-07-07 16:51:11,800 INFO] step: 180, mrr: 93.4, Acc@1: 87.05
[2025-07-07 16:51:12,887 INFO] {'loss': 0.3458, 'grad_norm': 16.36260414123535, 'learning_rate': 1.5191690673018861e-05, 'epoch': 0.12156110044785669}
[2025-07-07 16:51:12,917 INFO] step: 190, mrr: 93.44, Acc@1: 87.17
[2025-07-07 16:51:14,044 INFO] {'loss': 0.2079, 'grad_norm': 12.777920722961426, 'learning_rate': 1.5340199971093208e-05, 'epoch': 0.12795905310300704}
[2025-07-07 16:51:14,069 INFO] step: 200, mrr: 93.49, Acc@1: 87.28
[2025-07-07 16:51:15,194 INFO] {'loss': 0.1913, 'grad_norm': 18.09288215637207, 'learning_rate': 1.5481461964892795e-05, 'epoch': 0.1343570057581574}
[2025-07-07 16:51:15,231 INFO] step: 210, mrr: 93.59, Acc@1: 87.53
[2025-07-07 16:51:16,363 INFO] {'loss': 0.2336, 'grad_norm': 7.977358818054199, 'learning_rate': 1.5616151205481378e-05, 'epoch': 0.14075495841330773}
[2025-07-07 16:51:16,397 INFO] step: 220, mrr: 93.71, Acc@1: 87.75
[2025-07-07 16:51:17,580 INFO] {'loss': 0.2044, 'grad_norm': 8.950390815734863, 'learning_rate': 1.5744852240117287e-05, 'epoch': 0.1471529110684581}
[2025-07-07 16:51:17,607 INFO] step: 230, mrr: 93.75, Acc@1: 87.82
[2025-07-07 16:51:18,714 INFO] {'loss': 0.1545, 'grad_norm': 8.581847190856934, 'learning_rate': 1.586807494474404e-05, 'epoch': 0.15355086372360843}
[2025-07-07 16:51:18,741 INFO] step: 240, mrr: 93.89, Acc@1: 88.1
[2025-07-07 16:51:19,822 INFO] {'loss': 0.2346, 'grad_norm': 7.07781982421875, 'learning_rate': 1.598626672448025e-05, 'epoch': 0.1599488163787588}
[2025-07-07 16:51:19,846 INFO] step: 250, mrr: 93.91, Acc@1: 88.12
[2025-07-07 16:51:20,967 INFO] {'loss': 0.1823, 'grad_norm': 6.255715370178223, 'learning_rate': 1.6099822319805453e-05, 'epoch': 0.16634676903390916}
[2025-07-07 16:51:20,997 INFO] step: 260, mrr: 94.01, Acc@1: 88.31
[2025-07-07 16:51:22,112 INFO] {'loss': 0.3159, 'grad_norm': 18.626401901245117, 'learning_rate': 1.620909176105992e-05, 'epoch': 0.1727447216890595}
[2025-07-07 16:51:22,136 INFO] step: 270, mrr: 94.03, Acc@1: 88.33
[2025-07-07 16:51:23,233 INFO] {'loss': 0.1577, 'grad_norm': 18.69927215576172, 'learning_rate': 1.6314386875614796e-05, 'epoch': 0.17914267434420986}
[2025-07-07 16:51:23,257 INFO] step: 280, mrr: 94.13, Acc@1: 88.55
[2025-07-07 16:51:24,380 INFO] {'loss': 0.207, 'grad_norm': 19.839082717895508, 'learning_rate': 1.6415986652659708e-05, 'epoch': 0.1855406269993602}
[2025-07-07 16:51:24,415 INFO] step: 290, mrr: 94.17, Acc@1: 88.62
[2025-07-07 16:51:25,573 INFO] {'loss': 0.2088, 'grad_norm': 26.85717010498047, 'learning_rate': 1.6514141698131085e-05, 'epoch': 0.19193857965451055}
[2025-07-07 16:51:25,597 INFO] step: 300, mrr: 94.23, Acc@1: 88.73
[2025-07-07 16:51:26,690 INFO] {'loss': 0.2073, 'grad_norm': 31.582874298095703, 'learning_rate': 1.6609077958895154e-05, 'epoch': 0.19833653230966092}
[2025-07-07 16:51:26,716 INFO] step: 310, mrr: 94.26, Acc@1: 88.79
[2025-07-07 16:51:27,806 INFO] {'loss': 0.1938, 'grad_norm': 23.773019790649414, 'learning_rate': 1.670099985546604e-05, 'epoch': 0.20473448496481125}
[2025-07-07 16:51:27,840 INFO] step: 320, mrr: 94.3, Acc@1: 88.84
[2025-07-07 16:51:28,944 INFO] {'loss': 0.176, 'grad_norm': 9.710785865783691, 'learning_rate': 1.679009293251925e-05, 'epoch': 0.21113243761996162}
[2025-07-07 16:51:28,974 INFO] step: 330, mrr: 94.34, Acc@1: 88.94
[2025-07-07 16:51:30,129 INFO] {'loss': 0.2199, 'grad_norm': 16.45360565185547, 'learning_rate': 1.6876526113615038e-05, 'epoch': 0.21753039027511195}
[2025-07-07 16:51:30,164 INFO] step: 340, mrr: 94.42, Acc@1: 89.08
[2025-07-07 16:51:31,226 INFO] {'loss': 0.213, 'grad_norm': 13.879708290100098, 'learning_rate': 1.6960453629001838e-05, 'epoch': 0.22392834293026231}
[2025-07-07 16:51:31,257 INFO] step: 350, mrr: 94.43, Acc@1: 89.1
[2025-07-07 16:51:32,427 INFO] {'loss': 0.1876, 'grad_norm': 23.309844970703125, 'learning_rate': 1.704201667178192e-05, 'epoch': 0.23032629558541268}
[2025-07-07 16:51:32,455 INFO] step: 360, mrr: 94.51, Acc@1: 89.28
[2025-07-07 16:51:33,633 INFO] {'loss': 0.0645, 'grad_norm': 12.62234878540039, 'learning_rate': 1.7121344827113302e-05, 'epoch': 0.236724248240563}
[2025-07-07 16:51:33,666 INFO] step: 370, mrr: 94.62, Acc@1: 89.5
[2025-07-07 16:51:34,808 INFO] {'loss': 0.1947, 'grad_norm': 7.521234035491943, 'learning_rate': 1.7198557310778737e-05, 'epoch': 0.24312220089571338}
[2025-07-07 16:51:34,842 INFO] step: 380, mrr: 94.64, Acc@1: 89.57
[2025-07-07 16:51:35,993 INFO] {'loss': 0.1643, 'grad_norm': 18.7154541015625, 'learning_rate': 1.727376404684333e-05, 'epoch': 0.2495201535508637}
[2025-07-07 16:51:36,027 INFO] step: 390, mrr: 94.72, Acc@1: 89.71
[2025-07-07 16:51:37,144 INFO] {'loss': 0.1978, 'grad_norm': 10.838286399841309, 'learning_rate': 1.7347066608853085e-05, 'epoch': 0.2559181062060141}
[2025-07-07 16:51:37,175 INFO] step: 400, mrr: 94.74, Acc@1: 89.76
[2025-07-07 16:51:38,270 INFO] {'loss': 0.1669, 'grad_norm': 5.502222537994385, 'learning_rate': 1.741855904479824e-05, 'epoch': 0.26231605886116444}
[2025-07-07 16:51:38,301 INFO] step: 410, mrr: 94.8, Acc@1: 89.87
[2025-07-07 16:51:39,430 INFO] {'loss': 0.1553, 'grad_norm': 13.044353485107422, 'learning_rate': 1.748832860265267e-05, 'epoch': 0.2687140115163148}
[2025-07-07 16:51:39,461 INFO] step: 420, mrr: 94.82, Acc@1: 89.9
[2025-07-07 16:51:40,561 INFO] {'loss': 0.2047, 'grad_norm': 16.502195358276367, 'learning_rate': 1.755645637053058e-05, 'epoch': 0.2751119641714651}
[2025-07-07 16:51:40,591 INFO] step: 430, mrr: 94.84, Acc@1: 89.95
[2025-07-07 16:51:41,653 INFO] {'loss': 0.2634, 'grad_norm': 14.514131546020508, 'learning_rate': 1.762301784324125e-05, 'epoch': 0.28150991682661547}
[2025-07-07 16:51:41,688 INFO] step: 440, mrr: 94.86, Acc@1: 89.99
[2025-07-07 16:51:42,832 INFO] {'loss': 0.2897, 'grad_norm': 15.383578300476074, 'learning_rate': 1.768808342516896e-05, 'epoch': 0.28790786948176583}
[2025-07-07 16:51:42,866 INFO] step: 450, mrr: 94.82, Acc@1: 89.93
[2025-07-07 16:51:44,007 INFO] {'loss': 0.1839, 'grad_norm': 16.95208168029785, 'learning_rate': 1.7751718877877165e-05, 'epoch': 0.2943058221369162}
[2025-07-07 16:51:44,041 INFO] step: 460, mrr: 94.81, Acc@1: 89.9
[2025-07-07 16:51:45,130 INFO] {'loss': 0.268, 'grad_norm': 18.667476654052734, 'learning_rate': 1.781398571957145e-05, 'epoch': 0.30070377479206656}
[2025-07-07 16:51:45,158 INFO] step: 470, mrr: 94.82, Acc@1: 89.9
[2025-07-07 16:51:46,241 INFO] {'loss': 0.111, 'grad_norm': 7.1906914710998535, 'learning_rate': 1.7874941582503917e-05, 'epoch': 0.30710172744721687}
[2025-07-07 16:51:46,269 INFO] step: 480, mrr: 94.88, Acc@1: 90.02
[2025-07-07 16:51:47,380 INFO] {'loss': 0.1952, 'grad_norm': 9.638829231262207, 'learning_rate': 1.7934640533523426e-05, 'epoch': 0.31349968010236723}
[2025-07-07 16:51:47,412 INFO] step: 490, mrr: 94.93, Acc@1: 90.11
[2025-07-07 16:51:48,483 INFO] {'loss': 0.1735, 'grad_norm': 12.488972663879395, 'learning_rate': 1.7993133362240127e-05, 'epoch': 0.3198976327575176}
[2025-07-07 16:51:48,509 INFO] step: 500, mrr: 94.96, Acc@1: 90.18
[2025-07-07 16:51:49,630 INFO] {'loss': 0.1517, 'grad_norm': 9.357522964477539, 'learning_rate': 1.805046784065291e-05, 'epoch': 0.32629558541266795}
[2025-07-07 16:51:49,659 INFO] step: 510, mrr: 94.98, Acc@1: 90.22
[2025-07-07 16:51:50,763 INFO] {'loss': 0.2238, 'grad_norm': 14.911588668823242, 'learning_rate': 1.810668895756533e-05, 'epoch': 0.3326935380678183}
[2025-07-07 16:51:50,792 INFO] step: 520, mrr: 95.0, Acc@1: 90.26
[2025-07-07 16:51:51,939 INFO] {'loss': 0.142, 'grad_norm': 16.671358108520508, 'learning_rate': 1.816183913067193e-05, 'epoch': 0.3390914907229686}
[2025-07-07 16:51:51,962 INFO] step: 530, mrr: 95.02, Acc@1: 90.3
[2025-07-07 16:51:53,020 INFO] {'loss': 0.1457, 'grad_norm': 2.8385682106018066, 'learning_rate': 1.8215958398819793e-05, 'epoch': 0.345489443378119}
[2025-07-07 16:51:53,054 INFO] step: 540, mrr: 95.07, Acc@1: 90.4
[2025-07-07 16:51:54,166 INFO] {'loss': 0.1678, 'grad_norm': 5.945840835571289, 'learning_rate': 1.8269084596628294e-05, 'epoch': 0.35188739603326935}
[2025-07-07 16:51:54,196 INFO] step: 550, mrr: 95.04, Acc@1: 90.35
[2025-07-07 16:51:55,317 INFO] {'loss': 0.1839, 'grad_norm': 7.4368205070495605, 'learning_rate': 1.832125351337467e-05, 'epoch': 0.3582853486884197}
[2025-07-07 16:51:55,353 INFO] step: 560, mrr: 95.06, Acc@1: 90.4
[2025-07-07 16:51:56,473 INFO] {'loss': 0.1675, 'grad_norm': 11.550496101379395, 'learning_rate': 1.8372499037816614e-05, 'epoch': 0.3646833013435701}
[2025-07-07 16:51:56,505 INFO] step: 570, mrr: 95.11, Acc@1: 90.48
[2025-07-07 16:51:57,580 INFO] {'loss': 0.2074, 'grad_norm': 14.944616317749023, 'learning_rate': 1.8422853290419585e-05, 'epoch': 0.3710812539987204}
[2025-07-07 16:51:57,609 INFO] step: 580, mrr: 95.13, Acc@1: 90.52
[2025-07-07 16:51:58,721 INFO] {'loss': 0.1042, 'grad_norm': 14.263846397399902, 'learning_rate': 1.847234674428096e-05, 'epoch': 0.37747920665387075}
[2025-07-07 16:51:58,751 INFO] step: 590, mrr: 95.17, Acc@1: 90.6
[2025-07-07 16:51:59,842 INFO] {'loss': 0.2298, 'grad_norm': 5.696651935577393, 'learning_rate': 1.852100833589096e-05, 'epoch': 0.3838771593090211}
[2025-07-07 16:51:59,868 INFO] step: 600, mrr: 95.18, Acc@1: 90.61
[2025-07-07 16:52:00,945 INFO] {'loss': 0.1917, 'grad_norm': 10.738590240478516, 'learning_rate': 1.856886556673845e-05, 'epoch': 0.3902751119641715}
[2025-07-07 16:52:00,975 INFO] step: 610, mrr: 95.19, Acc@1: 90.63
[2025-07-07 16:52:02,104 INFO] {'loss': 0.18, 'grad_norm': 26.533273696899414, 'learning_rate': 1.861594459665503e-05, 'epoch': 0.39667306461932184}
[2025-07-07 16:52:02,135 INFO] step: 620, mrr: 95.2, Acc@1: 90.64
[2025-07-07 16:52:03,247 INFO] {'loss': 0.2244, 'grad_norm': 16.26885986328125, 'learning_rate': 1.866227032969055e-05, 'epoch': 0.40307101727447214}
[2025-07-07 16:52:03,282 INFO] step: 630, mrr: 95.2, Acc@1: 90.64
[2025-07-07 16:52:04,363 INFO] {'loss': 0.1836, 'grad_norm': 30.349836349487305, 'learning_rate': 1.8707866493225918e-05, 'epoch': 0.4094689699296225}
[2025-07-07 16:52:04,393 INFO] step: 640, mrr: 95.22, Acc@1: 90.68
[2025-07-07 16:52:05,538 INFO] {'loss': 0.2201, 'grad_norm': 27.14357566833496, 'learning_rate': 1.8752755710952372e-05, 'epoch': 0.41586692258477287}
[2025-07-07 16:52:05,567 INFO] step: 650, mrr: 95.22, Acc@1: 90.68
[2025-07-07 16:52:06,648 INFO] {'loss': 0.123, 'grad_norm': 16.247478485107422, 'learning_rate': 1.879695957027913e-05, 'epoch': 0.42226487523992323}
[2025-07-07 16:52:06,680 INFO] step: 660, mrr: 95.25, Acc@1: 90.74
[2025-07-07 16:52:07,765 INFO] {'loss': 0.2157, 'grad_norm': 28.357004165649414, 'learning_rate': 1.8840498684672176e-05, 'epoch': 0.4286628278950736}
[2025-07-07 16:52:07,791 INFO] step: 670, mrr: 95.26, Acc@1: 90.75
[2025-07-07 16:52:08,880 INFO] {'loss': 0.1435, 'grad_norm': 12.586716651916504, 'learning_rate': 1.888339275137491e-05, 'epoch': 0.4350607805502239}
[2025-07-07 16:52:08,914 INFO] step: 680, mrr: 95.28, Acc@1: 90.79
[2025-07-07 16:52:10,021 INFO] {'loss': 0.2044, 'grad_norm': 19.585126876831055, 'learning_rate': 1.892566060491504e-05, 'epoch': 0.44145873320537427}
[2025-07-07 16:52:10,055 INFO] step: 690, mrr: 95.29, Acc@1: 90.82
[2025-07-07 16:52:11,179 INFO] {'loss': 0.1646, 'grad_norm': 18.133544921875, 'learning_rate': 1.8967320266761712e-05, 'epoch': 0.44785668586052463}
[2025-07-07 16:52:11,207 INFO] step: 700, mrr: 95.31, Acc@1: 90.85
[2025-07-07 16:52:12,298 INFO] {'loss': 0.2605, 'grad_norm': 24.30908203125, 'learning_rate': 1.9008388991460504e-05, 'epoch': 0.454254638515675}
[2025-07-07 16:52:12,322 INFO] step: 710, mrr: 95.31, Acc@1: 90.85
[2025-07-07 16:52:13,374 INFO] {'loss': 0.2317, 'grad_norm': 5.647637844085693, 'learning_rate': 1.9048883309541794e-05, 'epoch': 0.46065259117082535}
[2025-07-07 16:52:13,400 INFO] step: 720, mrr: 95.32, Acc@1: 90.87
[2025-07-07 16:52:14,490 INFO] {'loss': 0.2517, 'grad_norm': 10.83434772491455, 'learning_rate': 1.908881906746971e-05, 'epoch': 0.46705054382597566}
[2025-07-07 16:52:14,520 INFO] step: 730, mrr: 95.32, Acc@1: 90.86
[2025-07-07 16:52:15,676 INFO] {'loss': 0.2008, 'grad_norm': 26.159669876098633, 'learning_rate': 1.9128211464873177e-05, 'epoch': 0.473448496481126}
[2025-07-07 16:52:15,711 INFO] step: 740, mrr: 95.32, Acc@1: 90.87
[2025-07-07 16:52:16,872 INFO] {'loss': 0.1738, 'grad_norm': 1.442221760749817, 'learning_rate': 1.9167075089278e-05, 'epoch': 0.4798464491362764}
[2025-07-07 16:52:16,906 INFO] step: 750, mrr: 95.35, Acc@1: 90.92
[2025-07-07 16:52:18,069 INFO] {'loss': 0.2286, 'grad_norm': 5.611855506896973, 'learning_rate': 1.920542394853861e-05, 'epoch': 0.48624440179142675}
[2025-07-07 16:52:18,100 INFO] step: 760, mrr: 95.35, Acc@1: 90.92
[2025-07-07 16:52:19,240 INFO] {'loss': 0.1531, 'grad_norm': 4.04149055480957, 'learning_rate': 1.924327150114988e-05, 'epoch': 0.4926423544465771}
[2025-07-07 16:52:19,274 INFO] step: 770, mrr: 95.38, Acc@1: 90.96
[2025-07-07 16:52:20,439 INFO] {'loss': 0.1791, 'grad_norm': 11.567811012268066, 'learning_rate': 1.9280630684603204e-05, 'epoch': 0.4990403071017274}
[2025-07-07 16:52:20,464 INFO] step: 780, mrr: 95.39, Acc@1: 90.98
[2025-07-07 16:52:21,603 INFO] {'loss': 0.1222, 'grad_norm': 16.269241333007812, 'learning_rate': 1.931751394193628e-05, 'epoch': 0.5054382597568778}
[2025-07-07 16:52:21,637 INFO] step: 790, mrr: 95.41, Acc@1: 91.02
[2025-07-07 16:52:22,715 INFO] {'loss': 0.0824, 'grad_norm': 9.726593971252441, 'learning_rate': 1.935393324661296e-05, 'epoch': 0.5118362124120281}
[2025-07-07 16:52:22,749 INFO] step: 800, mrr: 95.44, Acc@1: 91.09
[2025-07-07 16:52:23,899 INFO] {'loss': 0.2083, 'grad_norm': 18.47919273376465, 'learning_rate': 1.9389900125857667e-05, 'epoch': 0.5182341650671785}
[2025-07-07 16:52:23,925 INFO] step: 810, mrr: 95.44, Acc@1: 91.09
[2025-07-07 16:52:25,017 INFO] {'loss': 0.2231, 'grad_norm': 21.386459350585938, 'learning_rate': 1.9425425682558113e-05, 'epoch': 0.5246321177223289}
[2025-07-07 16:52:25,044 INFO] step: 820, mrr: 95.45, Acc@1: 91.1
[2025-07-07 16:52:26,125 INFO] {'loss': 0.2534, 'grad_norm': 17.913652420043945, 'learning_rate': 1.9460520615840494e-05, 'epoch': 0.5310300703774792}
[2025-07-07 16:52:26,158 INFO] step: 830, mrr: 95.44, Acc@1: 91.09
[2025-07-07 16:52:27,266 INFO] {'loss': 0.1899, 'grad_norm': 1.0122536420822144, 'learning_rate': 1.9495195240412547e-05, 'epoch': 0.5374280230326296}
[2025-07-07 16:52:27,293 INFO] step: 840, mrr: 95.46, Acc@1: 91.12
[2025-07-07 16:52:28,394 INFO] {'loss': 0.1525, 'grad_norm': 7.383693218231201, 'learning_rate': 1.9529459504761957e-05, 'epoch': 0.5438259756877799}
[2025-07-07 16:52:28,425 INFO] step: 850, mrr: 95.48, Acc@1: 91.15
[2025-07-07 16:52:29,493 INFO] {'loss': 0.2594, 'grad_norm': 14.64803695678711, 'learning_rate': 1.9563323008290453e-05, 'epoch': 0.5502239283429302}
[2025-07-07 16:52:29,525 INFO] step: 860, mrr: 95.47, Acc@1: 91.14
[2025-07-07 16:52:30,600 INFO] {'loss': 0.1741, 'grad_norm': 21.665000915527344, 'learning_rate': 1.959679501745746e-05, 'epoch': 0.5566218809980806}
[2025-07-07 16:52:30,631 INFO] step: 870, mrr: 95.48, Acc@1: 91.17
[2025-07-07 16:52:31,749 INFO] {'loss': 0.1848, 'grad_norm': 13.21004581451416, 'learning_rate': 1.9629884481001123e-05, 'epoch': 0.5630198336532309}
[2025-07-07 16:52:31,776 INFO] step: 880, mrr: 95.48, Acc@1: 91.16
[2025-07-07 16:52:32,900 INFO] {'loss': 0.1952, 'grad_norm': 23.822072982788086, 'learning_rate': 1.966260004429942e-05, 'epoch': 0.5694177863083814}
[2025-07-07 16:52:32,928 INFO] step: 890, mrr: 95.47, Acc@1: 91.14
[2025-07-07 16:52:34,038 INFO] {'loss': 0.1796, 'grad_norm': 18.25637435913086, 'learning_rate': 1.9694950062928836e-05, 'epoch': 0.5758157389635317}
[2025-07-07 16:52:34,070 INFO] step: 900, mrr: 95.48, Acc@1: 91.16
[2025-07-07 16:52:35,189 INFO] {'loss': 0.2274, 'grad_norm': 16.395971298217773, 'learning_rate': 1.9726942615473957e-05, 'epoch': 0.582213691618682}
[2025-07-07 16:52:35,215 INFO] step: 910, mrr: 95.48, Acc@1: 91.17
[2025-07-07 16:52:36,340 INFO] {'loss': 0.1805, 'grad_norm': 11.79452896118164, 'learning_rate': 1.975858551563704e-05, 'epoch': 0.5886116442738324}
[2025-07-07 16:52:36,374 INFO] step: 920, mrr: 95.49, Acc@1: 91.19
[2025-07-07 16:52:37,534 INFO] {'loss': 0.1886, 'grad_norm': 9.65447998046875, 'learning_rate': 1.9789886323692902e-05, 'epoch': 0.5950095969289827}
[2025-07-07 16:52:37,563 INFO] step: 930, mrr: 95.5, Acc@1: 91.2
[2025-07-07 16:52:38,630 INFO] {'loss': 0.277, 'grad_norm': 3.3622796535491943, 'learning_rate': 1.982085235733133e-05, 'epoch': 0.6014075495841331}
[2025-07-07 16:52:38,664 INFO] step: 940, mrr: 95.49, Acc@1: 91.17
[2025-07-07 16:52:39,698 INFO] {'loss': 0.2411, 'grad_norm': 2.825026035308838, 'learning_rate': 1.9851490701925657e-05, 'epoch': 0.6078055022392834}
[2025-07-07 16:52:39,732 INFO] step: 950, mrr: 95.49, Acc@1: 91.17
[2025-07-07 16:52:40,824 INFO] {'loss': 0.1586, 'grad_norm': 8.172359466552734, 'learning_rate': 1.988180822026379e-05, 'epoch': 0.6142034548944337}
[2025-07-07 16:52:40,854 INFO] step: 960, mrr: 95.5, Acc@1: 91.2
[2025-07-07 16:52:41,973 INFO] {'loss': 0.1947, 'grad_norm': 8.530984878540039, 'learning_rate': 1.991181156177497e-05, 'epoch': 0.6206014075495841}
[2025-07-07 16:52:42,003 INFO] step: 970, mrr: 95.49, Acc@1: 91.19
[2025-07-07 16:52:43,126 INFO] {'loss': 0.1995, 'grad_norm': 12.56038761138916, 'learning_rate': 1.99415071712833e-05, 'epoch': 0.6269993602047345}
[2025-07-07 16:52:43,153 INFO] step: 980, mrr: 95.51, Acc@1: 91.22
[2025-07-07 16:52:44,273 INFO] {'loss': 0.1771, 'grad_norm': 11.896193504333496, 'learning_rate': 1.9970901297317003e-05, 'epoch': 0.6333973128598849}
[2025-07-07 16:52:44,304 INFO] step: 990, mrr: 95.52, Acc@1: 91.24
[2025-07-07 16:52:45,432 INFO] {'loss': 0.1557, 'grad_norm': 10.51875114440918, 'learning_rate': 2e-05, 'epoch': 0.6397952655150352}
[2025-07-07 16:52:45,460 INFO] step: 1000, mrr: 95.53, Acc@1: 91.25
[2025-07-07 16:52:46,589 INFO] {'loss': 0.1386, 'grad_norm': 4.301155090332031, 'learning_rate': 1.9680284191829488e-05, 'epoch': 0.6461932181701855}
[2025-07-07 16:52:46,622 INFO] step: 1010, mrr: 95.55, Acc@1: 91.3
[2025-07-07 16:52:47,727 INFO] {'loss': 0.225, 'grad_norm': 11.770621299743652, 'learning_rate': 1.932504440497336e-05, 'epoch': 0.6525911708253359}
[2025-07-07 16:52:47,759 INFO] step: 1020, mrr: 95.55, Acc@1: 91.3
[2025-07-07 16:52:48,880 INFO] {'loss': 0.0901, 'grad_norm': 6.837001800537109, 'learning_rate': 1.896980461811723e-05, 'epoch': 0.6589891234804862}
[2025-07-07 16:52:48,913 INFO] step: 1030, mrr: 95.57, Acc@1: 91.34
[2025-07-07 16:52:50,004 INFO] {'loss': 0.092, 'grad_norm': 3.8969428539276123, 'learning_rate': 1.8614564831261103e-05, 'epoch': 0.6653870761356366}
[2025-07-07 16:52:50,038 INFO] step: 1040, mrr: 95.59, Acc@1: 91.38
[2025-07-07 16:52:51,147 INFO] {'loss': 0.1405, 'grad_norm': 8.233806610107422, 'learning_rate': 1.8259325044404975e-05, 'epoch': 0.6717850287907869}
[2025-07-07 16:52:51,175 INFO] step: 1050, mrr: 95.61, Acc@1: 91.42
[2025-07-07 16:52:52,225 INFO] {'loss': 0.1525, 'grad_norm': 6.691184997558594, 'learning_rate': 1.7904085257548847e-05, 'epoch': 0.6781829814459372}
[2025-07-07 16:52:52,255 INFO] step: 1060, mrr: 95.63, Acc@1: 91.46
[2025-07-07 16:52:53,393 INFO] {'loss': 0.1746, 'grad_norm': 9.356083869934082, 'learning_rate': 1.754884547069272e-05, 'epoch': 0.6845809341010877}
[2025-07-07 16:52:53,421 INFO] step: 1070, mrr: 95.64, Acc@1: 91.49
[2025-07-07 16:52:54,424 INFO] {'loss': 0.1933, 'grad_norm': 16.609804153442383, 'learning_rate': 1.719360568383659e-05, 'epoch': 0.690978886756238}
[2025-07-07 16:52:54,457 INFO] step: 1080, mrr: 95.64, Acc@1: 91.49
[2025-07-07 16:52:55,571 INFO] {'loss': 0.2611, 'grad_norm': 1.5485410690307617, 'learning_rate': 1.6838365896980463e-05, 'epoch': 0.6973768394113884}
[2025-07-07 16:52:55,605 INFO] step: 1090, mrr: 95.63, Acc@1: 91.47
[2025-07-07 16:52:56,699 INFO] {'loss': 0.1614, 'grad_norm': 1.96843421459198, 'learning_rate': 1.6483126110124335e-05, 'epoch': 0.7037747920665387}
[2025-07-07 16:52:56,729 INFO] step: 1100, mrr: 95.65, Acc@1: 91.5
[2025-07-07 16:52:57,862 INFO] {'loss': 0.234, 'grad_norm': 12.151501655578613, 'learning_rate': 1.6127886323268207e-05, 'epoch': 0.710172744721689}
[2025-07-07 16:52:57,891 INFO] step: 1110, mrr: 95.65, Acc@1: 91.51
[2025-07-07 16:52:58,995 INFO] {'loss': 0.2988, 'grad_norm': 17.226564407348633, 'learning_rate': 1.577264653641208e-05, 'epoch': 0.7165706973768394}
[2025-07-07 16:52:59,029 INFO] step: 1120, mrr: 95.65, Acc@1: 91.49
[2025-07-07 16:53:00,122 INFO] {'loss': 0.2421, 'grad_norm': 15.78657341003418, 'learning_rate': 1.541740674955595e-05, 'epoch': 0.7229686500319897}
[2025-07-07 16:53:00,153 INFO] step: 1130, mrr: 95.64, Acc@1: 91.48
[2025-07-07 16:53:01,208 INFO] {'loss': 0.2406, 'grad_norm': 18.977705001831055, 'learning_rate': 1.5062166962699824e-05, 'epoch': 0.7293666026871402}
[2025-07-07 16:53:01,236 INFO] step: 1140, mrr: 95.65, Acc@1: 91.49
[2025-07-07 16:53:02,386 INFO] {'loss': 0.1378, 'grad_norm': 3.159991979598999, 'learning_rate': 1.4706927175843695e-05, 'epoch': 0.7357645553422905}
[2025-07-07 16:53:02,419 INFO] step: 1150, mrr: 95.66, Acc@1: 91.51
[2025-07-07 16:53:03,531 INFO] {'loss': 0.2146, 'grad_norm': 3.321120262145996, 'learning_rate': 1.4351687388987568e-05, 'epoch': 0.7421625079974408}
[2025-07-07 16:53:03,562 INFO] step: 1160, mrr: 95.67, Acc@1: 91.54
[2025-07-07 16:53:04,671 INFO] {'loss': 0.177, 'grad_norm': 4.825720310211182, 'learning_rate': 1.399644760213144e-05, 'epoch': 0.7485604606525912}
[2025-07-07 16:53:04,699 INFO] step: 1170, mrr: 95.69, Acc@1: 91.56
[2025-07-07 16:53:05,763 INFO] {'loss': 0.1339, 'grad_norm': 5.188693523406982, 'learning_rate': 1.3641207815275312e-05, 'epoch': 0.7549584133077415}
[2025-07-07 16:53:05,797 INFO] step: 1180, mrr: 95.69, Acc@1: 91.58
[2025-07-07 16:53:06,873 INFO] {'loss': 0.2831, 'grad_norm': 9.367323875427246, 'learning_rate': 1.3285968028419186e-05, 'epoch': 0.7613563659628919}
[2025-07-07 16:53:06,901 INFO] step: 1190, mrr: 95.69, Acc@1: 91.57
[2025-07-07 16:53:07,944 INFO] {'loss': 0.1662, 'grad_norm': 0.5264788866043091, 'learning_rate': 1.2930728241563056e-05, 'epoch': 0.7677543186180422}
[2025-07-07 16:53:07,973 INFO] step: 1200, mrr: 95.7, Acc@1: 91.61
[2025-07-07 16:53:09,103 INFO] {'loss': 0.1778, 'grad_norm': 1.6546642780303955, 'learning_rate': 1.2575488454706928e-05, 'epoch': 0.7741522712731925}
[2025-07-07 16:53:09,137 INFO] step: 1210, mrr: 95.71, Acc@1: 91.63
[2025-07-07 16:53:10,221 INFO] {'loss': 0.1387, 'grad_norm': 2.3932974338531494, 'learning_rate': 1.22202486678508e-05, 'epoch': 0.780550223928343}
[2025-07-07 16:53:10,247 INFO] step: 1220, mrr: 95.72, Acc@1: 91.65
[2025-07-07 16:53:11,362 INFO] {'loss': 0.099, 'grad_norm': 1.5166023969650269, 'learning_rate': 1.1865008880994673e-05, 'epoch': 0.7869481765834933}
[2025-07-07 16:53:11,393 INFO] step: 1230, mrr: 95.74, Acc@1: 91.67
[2025-07-07 16:53:12,477 INFO] {'loss': 0.1941, 'grad_norm': 25.610254287719727, 'learning_rate': 1.1509769094138545e-05, 'epoch': 0.7933461292386437}
[2025-07-07 16:53:12,511 INFO] step: 1240, mrr: 95.75, Acc@1: 91.7
[2025-07-07 16:53:13,618 INFO] {'loss': 0.0881, 'grad_norm': 0.05901378393173218, 'learning_rate': 1.1154529307282415e-05, 'epoch': 0.799744081893794}
[2025-07-07 16:53:13,646 INFO] step: 1250, mrr: 95.77, Acc@1: 91.74
[2025-07-07 16:53:14,725 INFO] {'loss': 0.1779, 'grad_norm': 14.58959674835205, 'learning_rate': 1.0799289520426289e-05, 'epoch': 0.8061420345489443}
[2025-07-07 16:53:14,751 INFO] step: 1260, mrr: 95.77, Acc@1: 91.74
[2025-07-07 16:53:15,845 INFO] {'loss': 0.3913, 'grad_norm': 21.6322078704834, 'learning_rate': 1.0444049733570161e-05, 'epoch': 0.8125399872040947}
[2025-07-07 16:53:15,873 INFO] step: 1270, mrr: 95.76, Acc@1: 91.72
[2025-07-07 16:53:17,048 INFO] {'loss': 0.1234, 'grad_norm': 4.140684127807617, 'learning_rate': 1.0088809946714033e-05, 'epoch': 0.818937939859245}
[2025-07-07 16:53:17,073 INFO] step: 1280, mrr: 95.77, Acc@1: 91.73
[2025-07-07 16:53:18,189 INFO] {'loss': 0.2438, 'grad_norm': 15.9799165725708, 'learning_rate': 9.733570159857905e-06, 'epoch': 0.8253358925143954}
[2025-07-07 16:53:18,218 INFO] step: 1290, mrr: 95.77, Acc@1: 91.73
[2025-07-07 16:53:19,351 INFO] {'loss': 0.1521, 'grad_norm': 17.837230682373047, 'learning_rate': 9.378330373001777e-06, 'epoch': 0.8317338451695457}
[2025-07-07 16:53:19,378 INFO] step: 1300, mrr: 95.76, Acc@1: 91.7
[2025-07-07 16:53:20,466 INFO] {'loss': 0.1496, 'grad_norm': 19.366289138793945, 'learning_rate': 9.023090586145649e-06, 'epoch': 0.838131797824696}
[2025-07-07 16:53:20,496 INFO] step: 1310, mrr: 95.77, Acc@1: 91.73
[2025-07-07 16:53:21,576 INFO] {'loss': 0.1844, 'grad_norm': 11.741645812988281, 'learning_rate': 8.66785079928952e-06, 'epoch': 0.8445297504798465}
[2025-07-07 16:53:21,610 INFO] step: 1320, mrr: 95.78, Acc@1: 91.74
[2025-07-07 16:53:22,686 INFO] {'loss': 0.1416, 'grad_norm': 4.404954433441162, 'learning_rate': 8.312611012433394e-06, 'epoch': 0.8509277031349968}
[2025-07-07 16:53:22,720 INFO] step: 1330, mrr: 95.79, Acc@1: 91.75
[2025-07-07 16:53:23,862 INFO] {'loss': 0.2201, 'grad_norm': 3.3796768188476562, 'learning_rate': 7.957371225577264e-06, 'epoch': 0.8573256557901472}
[2025-07-07 16:53:23,888 INFO] step: 1340, mrr: 95.79, Acc@1: 91.76
[2025-07-07 16:53:25,008 INFO] {'loss': 0.199, 'grad_norm': 6.338332653045654, 'learning_rate': 7.602131438721138e-06, 'epoch': 0.8637236084452975}
[2025-07-07 16:53:25,042 INFO] step: 1350, mrr: 95.79, Acc@1: 91.77
[2025-07-07 16:53:26,197 INFO] {'loss': 0.0876, 'grad_norm': 7.0753912925720215, 'learning_rate': 7.246891651865009e-06, 'epoch': 0.8701215611004478}
[2025-07-07 16:53:26,231 INFO] step: 1360, mrr: 95.81, Acc@1: 91.81
[2025-07-07 16:53:27,359 INFO] {'loss': 0.2082, 'grad_norm': 28.488557815551758, 'learning_rate': 6.891651865008882e-06, 'epoch': 0.8765195137555982}
[2025-07-07 16:53:27,390 INFO] step: 1370, mrr: 95.82, Acc@1: 91.81
[2025-07-07 16:53:28,496 INFO] {'loss': 0.2025, 'grad_norm': 3.317534923553467, 'learning_rate': 6.536412078152754e-06, 'epoch': 0.8829174664107485}
[2025-07-07 16:53:28,527 INFO] step: 1380, mrr: 95.82, Acc@1: 91.82
[2025-07-07 16:53:29,657 INFO] {'loss': 0.1823, 'grad_norm': 14.930051803588867, 'learning_rate': 6.181172291296626e-06, 'epoch': 0.889315419065899}
[2025-07-07 16:53:29,690 INFO] step: 1390, mrr: 95.82, Acc@1: 91.81
[2025-07-07 16:53:30,873 INFO] {'loss': 0.1823, 'grad_norm': 10.827749252319336, 'learning_rate': 5.825932504440498e-06, 'epoch': 0.8957133717210493}
[2025-07-07 16:53:30,907 INFO] step: 1400, mrr: 95.82, Acc@1: 91.81
[2025-07-07 16:53:32,083 INFO] {'loss': 0.2402, 'grad_norm': 13.499781608581543, 'learning_rate': 5.4706927175843694e-06, 'epoch': 0.9021113243761996}
[2025-07-07 16:53:32,117 INFO] step: 1410, mrr: 95.82, Acc@1: 91.81
[2025-07-07 16:53:33,253 INFO] {'loss': 0.1758, 'grad_norm': 3.2013065814971924, 'learning_rate': 5.115452930728242e-06, 'epoch': 0.90850927703135}
[2025-07-07 16:53:33,284 INFO] step: 1420, mrr: 95.83, Acc@1: 91.84
[2025-07-07 16:53:34,404 INFO] {'loss': 0.0867, 'grad_norm': 15.290853500366211, 'learning_rate': 4.760213143872114e-06, 'epoch': 0.9149072296865003}
[2025-07-07 16:53:34,434 INFO] step: 1430, mrr: 95.84, Acc@1: 91.86
[2025-07-07 16:53:35,593 INFO] {'loss': 0.1111, 'grad_norm': 9.801905632019043, 'learning_rate': 4.404973357015986e-06, 'epoch': 0.9213051823416507}
[2025-07-07 16:53:35,626 INFO] step: 1440, mrr: 95.85, Acc@1: 91.87
[2025-07-07 16:53:36,762 INFO] {'loss': 0.15, 'grad_norm': 24.2956485748291, 'learning_rate': 4.049733570159858e-06, 'epoch': 0.927703134996801}
[2025-07-07 16:53:36,789 INFO] step: 1450, mrr: 95.85, Acc@1: 91.87
[2025-07-07 16:53:37,937 INFO] {'loss': 0.2762, 'grad_norm': 17.514053344726562, 'learning_rate': 3.6944937833037303e-06, 'epoch': 0.9341010876519513}
[2025-07-07 16:53:37,971 INFO] step: 1460, mrr: 95.85, Acc@1: 91.87
[2025-07-07 16:53:39,087 INFO] {'loss': 0.1396, 'grad_norm': 9.549420356750488, 'learning_rate': 3.339253996447602e-06, 'epoch': 0.9404990403071017}
[2025-07-07 16:53:39,115 INFO] step: 1470, mrr: 95.86, Acc@1: 91.9
[2025-07-07 16:53:40,264 INFO] {'loss': 0.2793, 'grad_norm': 7.920143127441406, 'learning_rate': 2.984014209591474e-06, 'epoch': 0.946896992962252}
[2025-07-07 16:53:40,287 INFO] step: 1480, mrr: 95.85, Acc@1: 91.87
[2025-07-07 16:53:41,396 INFO] {'loss': 0.1896, 'grad_norm': 15.631558418273926, 'learning_rate': 2.628774422735347e-06, 'epoch': 0.9532949456174025}
[2025-07-07 16:53:41,421 INFO] step: 1490, mrr: 95.85, Acc@1: 91.88
[2025-07-07 16:53:42,458 INFO] {'loss': 0.2459, 'grad_norm': 13.796676635742188, 'learning_rate': 2.273534635879219e-06, 'epoch': 0.9596928982725528}
[2025-07-07 16:53:42,492 INFO] step: 1500, mrr: 95.85, Acc@1: 91.87
[2025-07-07 16:53:43,587 INFO] {'loss': 0.2809, 'grad_norm': 23.449979782104492, 'learning_rate': 1.9182948490230907e-06, 'epoch': 0.9660908509277031}
[2025-07-07 16:53:43,618 INFO] step: 1510, mrr: 95.86, Acc@1: 91.88
[2025-07-07 16:53:44,727 INFO] {'loss': 0.0887, 'grad_norm': 6.931779861450195, 'learning_rate': 1.563055062166963e-06, 'epoch': 0.9724888035828535}
[2025-07-07 16:53:44,761 INFO] step: 1520, mrr: 95.87, Acc@1: 91.9
[2025-07-07 16:53:45,882 INFO] {'loss': 0.2303, 'grad_norm': 22.55611228942871, 'learning_rate': 1.207815275310835e-06, 'epoch': 0.9788867562380038}
[2025-07-07 16:53:45,916 INFO] step: 1530, mrr: 95.86, Acc@1: 91.88
[2025-07-07 16:53:47,018 INFO] {'loss': 0.2113, 'grad_norm': 16.502248764038086, 'learning_rate': 8.52575488454707e-07, 'epoch': 0.9852847088931542}
[2025-07-07 16:53:47,052 INFO] step: 1540, mrr: 95.87, Acc@1: 91.9
[2025-07-07 16:53:48,202 INFO] {'loss': 0.1634, 'grad_norm': 15.559881210327148, 'learning_rate': 4.97335701598579e-07, 'epoch': 0.9916826615483045}
[2025-07-07 16:53:48,232 INFO] step: 1550, mrr: 95.88, Acc@1: 91.92
[2025-07-07 16:53:49,339 INFO] {'loss': 0.0861, 'grad_norm': 10.888811111450195, 'learning_rate': 1.4209591474245118e-07, 'epoch': 0.9980806142034548}
[2025-07-07 16:53:49,373 INFO] step: 1560, mrr: 95.89, Acc@1: 91.94
[2025-07-10 12:08:29,362 INFO] gcc -pthread -B /venv/main/compiler_compat -fno-strict-overflow -Wsign-compare -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /venv/main/include -fPIC -O2 -isystem /venv/main/include -fPIC -c /tmp/tmp_6ob75tn/test.c -o /tmp/tmp_6ob75tn/test.o
[2025-07-10 12:08:29,377 INFO] gcc -pthread -B /venv/main/compiler_compat /tmp/tmp_6ob75tn/test.o -laio -o /tmp/tmp_6ob75tn/a.out
[2025-07-10 12:08:30,057 INFO] Args=Arguments(
_n_gpu=1,
accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
add_pooler=False,
add_prompts=True,
all_use_mask_token=<ALL_USE_MASK_TOKEN>,
auto_find_batch_size=False,
average_tokens_across_devices=False,
batch_eval_metrics=False,
bf16=False,
bf16_full_eval=False,
data_dir=None,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=4,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
dataloader_prefetch_factor=None,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=../ds_config.json,
disable_tqdm=True,
do_encode=False,
do_eval=True,
do_kd_biencoder=False,
do_kd_gen_score=False,
do_predict=False,
do_rerank=False,
do_search=False,
do_train=True,
dry_run=False,
encode_batch_size=256,
encode_in_path=None,
encode_save_dir=None,
encode_shard_size=2000000,
eval_accumulation_steps=None,
eval_delay=0,
eval_do_concat_batches=True,
eval_on_start=False,
eval_steps=0.25,
eval_strategy=IntervalStrategy.STEPS,
eval_use_gather_object=False,
fp16=True,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_contrastive_loss=False,
full_determinism=False,
gradient_accumulation_steps=2,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=Ehsanl/RetNLbase_sl,
hub_private_repo=None,
hub_revision=None,
hub_strategy=HubStrategy.EVERY_SAVE,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_for_metrics=[],
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
kd_cont_loss_weight=1.0,
kd_gen_score_batch_size=128,
kd_gen_score_n_neg=30,
kd_gen_score_split=dev,
kd_mask_hn=True,
l2_normalize=True,
label_names=['labels'],
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
liger_kernel_config=None,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=trainer_output/runs/Jul10_12-08-29_baa23c0806ef,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=IntervalStrategy.STEPS,
loss_scale=-1.0,
lr_scheduler_kwargs={},
lr_scheduler_type=SchedulerType.LINEAR,
max_grad_norm=1.0,
max_steps=-1,
max_train_samples=None,
metric_for_best_model=None,
model_name_or_path=intfloat/multilingual-e5-base,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=1.0,
optim=OptimizerNames.ADAMW_TORCH,
optim_args=None,
optim_target_modules=None,
out_dimension=768,
output_dir=trainer_output,
overwrite_output_dir=True,
p_max_len=500,
p_prompt=passage: ,
past_index=-1,
per_device_eval_batch_size=256,
per_device_train_batch_size=128,
prediction_loss_only=False,
push_to_hub=True,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
q_max_len=50,
q_prompt=query: ,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
rerank_batch_size=128,
rerank_depth=1000,
rerank_forward_factor=1,
rerank_in_path=,
rerank_max_length=256,
rerank_out_path=,
rerank_split=dev,
rerank_use_rdrop=False,
restore_callback_states_from_checkpoint=False,
resume_from_checkpoint=None,
rlm_decoder_layers=2,
rlm_decoder_mask_prob=0.5,
rlm_encoder_mask_prob=0.3,
rlm_freeze_generator=True,
rlm_generator_mlm_weight=0.2,
rlm_generator_model_name=google/electra-base-generator,
rlm_max_length=144,
rlm_num_eval_samples=4096,
run_name=trainer_output,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=0.25,
save_strategy=SaveStrategy.STEPS,
save_total_limit=4,
search_batch_size=128,
search_out_dir=,
search_split=dev,
search_topk=200,
seed=1234,
share_encoder=True,
skip_memory_metrics=True,
t=0.02,
t_warmup=False,
task_type=ir,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torch_empty_cache_steps=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
train_file=syn_ret_nl.jsonl,
train_n_passages=2,
train_tasks=sl,
use_cpu=False,
use_first_positive=False,
use_in_batch_negs=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_liger_kernel=False,
use_mps_device=False,
use_scaled_loss=True,
validation_file=None,
warmup_ratio=0.0,
warmup_steps=200,
weight_decay=0.0,
)
[2025-07-10 12:08:39,469 INFO] BiencoderModel(
  (lm_q): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (lm_p): XLMRobertaModel(
    (embeddings): XLMRobertaEmbeddings(
      (word_embeddings): Embedding(250002, 768, padding_idx=1)
      (position_embeddings): Embedding(514, 768, padding_idx=1)
      (token_type_embeddings): Embedding(1, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): XLMRobertaEncoder(
      (layer): ModuleList(
        (0-11): 12 x XLMRobertaLayer(
          (attention): XLMRobertaAttention(
            (self): XLMRobertaSdpaSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): XLMRobertaSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): XLMRobertaIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): XLMRobertaOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): XLMRobertaPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (cross_entropy): CrossEntropyLoss()
  (kl_loss_fn): KLDivLoss()
  (pooler): Identity()
)
[2025-07-10 12:08:39,550 INFO] Vocab size: 250002
[2025-07-10 12:09:10,825 INFO] Sample 115535 of the training set: {'task_type': 'sl', 'task_desc': 'Given a question, retrieve documents that can help to answer the question.', 'q': 'query: Wat zijn de emotionele en psychologische gevolgen voor nabestaanden na het verlies van een dierbare door een onverwacht overlijden?', 'pos': "passage: Het verlies van een geliefde door een plotseling overlijden, zoals een onverwacht verkeersongeval of een hartaanval, brengt een scala aan intense emoties met zich mee. Nabestaanden ervaren vaak rouw, shock, ontkenning en boosheid. De psychologische gevolgen kunnen langdurig zijn, wat zich uit in depressieve gevoelens, sentimenten van schuld of zelfbeschuldiging, en problemen met het verwerken van het verlies. Rouwprocessen variren van persoon tot persoon, maar het is algemeen erkend dat het verliezen van een dierbare door een onvoorziene gebeurtenis diepe emotionele impact heeft die vaak professionele ondersteuning vereist voor een gezonde verwerking. Daarnaast kunnen sociale relaties onder druk komen te staan doordat de nabestaanden zich terugtrekken of geconfronteerd worden met anderen die moeite hebben om hun gevoelens te begrijpen. Het is essentieel dat zij toegang hebben tot passende psychologische hulp en ondersteuningsgroepen om de rouw op een gezonde wijze te doorstaan en het verlies een plek te geven in hun leven.\n\nHet opbouwen van een nieuw levensritme na zo'n ingrijpende gebeurtenis kost tijd en geduld. In veel gevallen worden rouwende geconfronteerd met fysieke symptomen zoals slaapstoornissen, vermoeidheid en concentratieproblemen. Psychologisch gezien kunnen ze te maken krijgen met herhaalde herinneringen aan het moment van overlijden of traumatische gedachten, wat hun dagelijks functioneren aanzienlijk kan benvloeden. Het erkennen van de pijn en het zoeken van sociale steun vormen kritieke elementen in het verwerkingsproces. Daarnaast wordt steeds meer benadrukt dat het bespreekbaar maken van deze gevoelens en het uiten van emoties via therapie of steunende gesprekken bijdraagt aan een beter herstel. In de context van rouwverwerking speelt het accepteren van het verlies een centrale rol, wat vaak een intensief en langdurig proces is, maar uiteindelijk leidt tot een nieuw evenwicht in het leven van de nabestaanden.", 'neg': "passage: Elk jaar overlijden veel mensen in Nederland door weersinvloeden, en de overheid neemt maatregelen om de gevolgen te beperken. Wat veel mensen niet weten, is dat de infrastructuur rondom natuurrampen goed is ontwikkeld en dat noodhulp snel ter plekke kan zijn. Daarnaast worden er preventieve campagnes gevoerd om de bevolking bewust te maken van de gevaren en om levens te redden. Het is belangrijk dat burgers weten hoe ze zichzelf kunnen beschermen tijdens noodsituaties zoals overstromingen of stormen, en dat de lokale veiligheidsdiensten goed voorbereid zijn op verschillende scenario's. Door deze gentegreerde aanpak wordt de impact van natuurrampen verminderd en worden slachtoffers sneller geholpen, waardoor slachtoffers van dergelijke gebeurtenissen vaak sneller kunnen herstellen dan bij onverwachte persoonlijke tragedies.", 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-10 12:09:10,825 INFO] Sample 30631 of the training set: {'task_type': 'sl', 'task_desc': 'Given a question, retrieve documents that can help to answer the question.', 'q': 'query: Hoe wordt het weer aanstaande woensdag verwacht in Nederland?', 'pos': 'passage: Het weer in Nederland wordt de komende dagen gekenmerkt door wisselende omstandigheden. Over het algemeen wordt er een mix van bewolkte luchten en opklaringen verwacht, met temperaturen die variren tussen 12 en 18 graden Celsius. In de ochtend kunnen lokale mistbanken voorkomen, vooral in de laaglanden, maar deze zullen snel verdwijnen zodra de zon opkomt. Er is geen significante neerslag voorzien, waardoor het ideale weer oplevert voor buitenactiviteiten zoals wandelen of fietsen. Wat betreft wind, wordt er een lichte wind waargenomen uit het noordwesten, die geen grote invloed heeft op de comfort niveaus. De weersvoorspellingen voor woensdag wijzen op een relatief stabiel patroon, waarbij de kans op neerslag minimaal is. Dit maakt dat de dag geschikt is voor diverse buitenplannen zonder dat men zich grote zorgen hoeft te maken over de weersomstandigheden. De temperatuur kan gedurende de dag verder oplopen wanneer de zon doorbreekt, waardoor het een aangename dag wordt voor inwoners en toeristen. Over het algemeen biedt de weersituatie in Nederland een rustige en milde week, ideaal voor zowel werk- als recreatieve activiteiten. Het is altijd verstandig om de lokale weersvoorspelling kort voor vertrek te raadplegen voor de meest actuele informatie, aangezien het weer in Nederland snel kan veranderen.', 'neg': 'passage: De klimatologische veranderingen in Nederland hebben geleid tot een toename in de frequentie en intensiteit van stormen en hevige regenbuien. In de afgelopen decennia is er een duidelijke trend zichtbaar van hogere temperaturen en meer extreme weersomstandigheden. Deze ontwikkelingen hebben grote gevolgen voor de waterbeheerplannen en infrastructuur, waaronder de versterking van dijken en de verbetering van drainage systemen. De wetenschappelijke communities werken nauw samen om nauwkeurigere voorspellingen te doen en adaptieve strategien te ontwikkelen die de impact van klimaatverandering kunnen beperken. Behalve de fysieke veranderingen in het klimaat, spelen ook ecosystemen en biodiversiteit een belangrijke rol bij het weer en de resilience van natuurlijke systemen. Mogelijke oplossingen omvatten het vergroten van groene infrastructuren, zoals stadsparken en groene daken, die helpen om de temperatuur te reguleren en wateroverlast te verminderen. Daarnaast wordt er veel onderzoek gedaan naar het aanpassingsvermogen van landbouwsystemen en stedelijke gebieden. Het is cruciaal dat beleidsmakers, gemeenschappen en wetenschappers blijven samenwerken om de gevolgen van klimaatverandering te mitigeren en Nederland voor te bereiden op de toekomst.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-10 12:09:10,826 INFO] Sample 1963 of the training set: {'task_type': 'sl', 'task_desc': 'Given a claim, retrieve documents that support or refute it.', 'q': 'query: Waar ligt de Veluwe precies?', 'pos': 'passage: De Veluwe is een groot natuurgebied in het midden van Nederland, gelegen in de provincie Gelderland en deels in de provincie Utrecht. Het staat bekend om zijn uitgestrekte bossen, heidevelden en zandverstuivingen. De Veluwe beslaat ongeveer 1.000 vierkante kilometer en is een populaire bestemming voor wandelaars, fietsers en natuurliefhebbers. Belangrijke plaatsen rondom de Veluwe zijn Apeldoorn, Ede en Harderwijk. Door de variatie in landschappen is het gebied rijk aan diverse flora en fauna, waaronder wilde zwijnen, edelherten en vele vogelsoorten. Verschillende nationale parken, zoals Nationaal Park De Hoge Veluwe, maken deel uit van dit gebied.', 'neg': 'passage: Gelderland is een provincie in het oosten van Nederland met een gevarieerd landschap, varirend van rivieren tot heuvelachtige gebieden. De hoofdstad van Gelderland is Arnhem, bekend om zijn geschiedenis en cultuur. Het gebied is populair voor recreatie en bestaat uit meerdere natuurgebieden naast de Veluwe, zoals de Betuwe en de Achterhoek. Sommige delen van Gelderland worden gekenmerkt door landbouwgrond en kleine dorpen. Hoewel de provincie bekendstaat om haar natuurschoon, zijn er ook stedelijke gebieden met diverse economische activiteiten. De Veluwe is een onderdeel van Gelderland, maar het beslaat slechts een deel van dit grote gebied.', 'scores': {'pos': 1.0, 'neg': 0.0}}.
[2025-07-10 12:09:11,838 WARNING] Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 2. Using DeepSpeed's value.
[2025-07-10 12:10:17,932 INFO] {'loss': 0.363, 'grad_norm': 4.457652568817139, 'learning_rate': 4.345879896760937e-06, 'epoch': 0.01466275659824047}
[2025-07-10 12:10:18,146 INFO] step: 10, mrr: 92.39, Acc@1: 85.57
[2025-07-10 12:10:18,782 INFO] step: 10, mrr: 92.52, Acc@1: 85.8
[2025-07-10 12:10:30,992 INFO] {'loss': 0.2407, 'grad_norm': 2.819648265838623, 'learning_rate': 5.6541201032390644e-06, 'epoch': 0.02932551319648094}
[2025-07-10 12:10:31,208 INFO] step: 20, mrr: 94.12, Acc@1: 88.87
[2025-07-10 12:10:31,847 INFO] step: 20, mrr: 94.18, Acc@1: 88.97
[2025-07-10 12:10:44,074 INFO] {'loss': 0.1732, 'grad_norm': 2.5398693084716797, 'learning_rate': 6.419391565964472e-06, 'epoch': 0.04398826979472141}
[2025-07-10 12:10:44,291 INFO] step: 30, mrr: 95.05, Acc@1: 90.6
[2025-07-10 12:10:44,930 INFO] step: 30, mrr: 95.09, Acc@1: 90.68
[2025-07-10 12:10:57,168 INFO] {'loss': 0.1147, 'grad_norm': 2.656114101409912, 'learning_rate': 6.9623603097171925e-06, 'epoch': 0.05865102639296188}
[2025-07-10 12:10:57,384 INFO] step: 40, mrr: 95.82, Acc@1: 92.08
[2025-07-10 12:10:58,024 INFO] step: 40, mrr: 95.85, Acc@1: 92.14
[2025-07-10 12:11:10,256 INFO] {'loss': 0.0829, 'grad_norm': 3.396737813949585, 'learning_rate': 7.3835195870437456e-06, 'epoch': 0.07331378299120235}
[2025-07-10 12:11:10,473 INFO] step: 50, mrr: 96.4, Acc@1: 93.16
[2025-07-10 12:11:11,111 INFO] step: 50, mrr: 96.42, Acc@1: 93.21
[2025-07-10 12:11:23,338 INFO] {'loss': 0.0626, 'grad_norm': 1.8529777526855469, 'learning_rate': 7.7276317724426e-06, 'epoch': 0.08797653958944282}
[2025-07-10 12:11:23,555 INFO] step: 60, mrr: 96.82, Acc@1: 93.96
[2025-07-10 12:11:24,194 INFO] step: 60, mrr: 96.84, Acc@1: 93.99
[2025-07-10 12:11:36,442 INFO] {'loss': 0.0525, 'grad_norm': 2.0901644229888916, 'learning_rate': 8.018574479650967e-06, 'epoch': 0.10263929618768329}
[2025-07-10 12:11:36,659 INFO] step: 70, mrr: 97.16, Acc@1: 94.6
[2025-07-10 12:11:37,296 INFO] step: 70, mrr: 97.18, Acc@1: 94.63
[2025-07-10 12:11:49,532 INFO] {'loss': 0.0366, 'grad_norm': 2.181779623031616, 'learning_rate': 8.270600516195319e-06, 'epoch': 0.11730205278592376}
[2025-07-10 12:11:49,749 INFO] step: 80, mrr: 97.45, Acc@1: 95.14
[2025-07-10 12:11:50,388 INFO] step: 80, mrr: 97.46, Acc@1: 95.16
[2025-07-10 12:12:02,617 INFO] {'loss': 0.0277, 'grad_norm': 1.8935929536819458, 'learning_rate': 8.492903235168008e-06, 'epoch': 0.13196480938416422}
[2025-07-10 12:12:02,834 INFO] step: 90, mrr: 97.69, Acc@1: 95.61
[2025-07-10 12:12:03,472 INFO] step: 90, mrr: 97.7, Acc@1: 95.63
[2025-07-10 12:12:15,704 INFO] {'loss': 0.0321, 'grad_norm': 1.399030327796936, 'learning_rate': 8.691759793521874e-06, 'epoch': 0.1466275659824047}
[2025-07-10 12:12:15,921 INFO] step: 100, mrr: 97.87, Acc@1: 95.95
[2025-07-10 12:12:16,559 INFO] step: 100, mrr: 97.88, Acc@1: 95.96
[2025-07-10 12:12:28,780 INFO] {'loss': 0.0312, 'grad_norm': 2.791447162628174, 'learning_rate': 8.87164743182396e-06, 'epoch': 0.16129032258064516}
[2025-07-10 12:12:28,997 INFO] step: 110, mrr: 98.02, Acc@1: 96.22
[2025-07-10 12:12:29,635 INFO] step: 110, mrr: 98.02, Acc@1: 96.24
[2025-07-10 12:12:41,832 INFO] {'loss': 0.0199, 'grad_norm': 1.3265197277069092, 'learning_rate': 9.035871978920727e-06, 'epoch': 0.17595307917888564}
[2025-07-10 12:12:42,049 INFO] step: 120, mrr: 98.16, Acc@1: 96.5
[2025-07-10 12:12:42,688 INFO] step: 120, mrr: 98.16, Acc@1: 96.51
[2025-07-10 12:12:54,914 INFO] {'loss': 0.0251, 'grad_norm': 1.1537936925888062, 'learning_rate': 9.186943917681705e-06, 'epoch': 0.1906158357771261}
[2025-07-10 12:12:55,130 INFO] step: 130, mrr: 98.27, Acc@1: 96.71
[2025-07-10 12:12:55,769 INFO] step: 130, mrr: 98.28, Acc@1: 96.72
[2025-07-10 12:13:07,988 INFO] {'loss': 0.0252, 'grad_norm': 1.5751093626022339, 'learning_rate': 9.326814686129093e-06, 'epoch': 0.20527859237536658}
[2025-07-10 12:13:08,205 INFO] step: 140, mrr: 98.37, Acc@1: 96.9
[2025-07-10 12:13:08,843 INFO] step: 140, mrr: 98.38, Acc@1: 96.91
[2025-07-10 12:13:21,072 INFO] {'loss': 0.018, 'grad_norm': 1.397944450378418, 'learning_rate': 9.457031256247281e-06, 'epoch': 0.21994134897360704}
[2025-07-10 12:13:21,289 INFO] step: 150, mrr: 98.46, Acc@1: 97.06
[2025-07-10 12:13:21,928 INFO] step: 150, mrr: 98.46, Acc@1: 97.07
[2025-07-10 12:13:34,146 INFO] {'loss': 0.0174, 'grad_norm': 1.8713263273239136, 'learning_rate': 9.578840722673449e-06, 'epoch': 0.23460410557184752}
[2025-07-10 12:13:34,362 INFO] step: 160, mrr: 98.54, Acc@1: 97.21
[2025-07-10 12:13:35,000 INFO] step: 160, mrr: 98.54, Acc@1: 97.22
[2025-07-10 12:13:47,228 INFO] {'loss': 0.0134, 'grad_norm': 3.00508451461792, 'learning_rate': 9.693263128169957e-06, 'epoch': 0.24926686217008798}
[2025-07-10 12:13:47,445 INFO] step: 170, mrr: 98.61, Acc@1: 97.35
[2025-07-10 12:13:48,083 INFO] step: 170, mrr: 98.62, Acc@1: 97.36
[2025-07-10 12:14:24,056 INFO] {'eval_loss': 0.0149688720703125, 'eval_mrr': 99.76599884033203, 'eval_acc1': 99.5320053100586, 'eval_runtime': 35.5177, 'eval_samples_per_second': 703.874, 'eval_steps_per_second': 2.759, 'epoch': 0.250733137829912}
[2025-07-10 12:14:24,697 INFO] Saving model checkpoint to trainer_output/checkpoint-171
[2025-07-10 12:14:41,026 INFO] {'loss': 0.0184, 'grad_norm': 2.280578374862671, 'learning_rate': 9.801143441646136e-06, 'epoch': 0.26392961876832843}
[2025-07-10 12:14:41,242 INFO] step: 180, mrr: 98.67, Acc@1: 97.47
[2025-07-10 12:14:41,880 INFO] step: 180, mrr: 98.67, Acc@1: 97.47
[2025-07-10 12:14:54,103 INFO] {'loss': 0.019, 'grad_norm': 1.4560539722442627, 'learning_rate': 9.903189464052494e-06, 'epoch': 0.2785923753665689}
[2025-07-10 12:14:54,320 INFO] step: 190, mrr: 98.72, Acc@1: 97.57
[2025-07-10 12:14:54,957 INFO] step: 190, mrr: 98.73, Acc@1: 97.57
[2025-07-10 12:15:07,154 INFO] {'loss': 0.015, 'grad_norm': 1.6423228979110718, 'learning_rate': 1e-05, 'epoch': 0.2932551319648094}
[2025-07-10 12:15:07,370 INFO] step: 200, mrr: 98.78, Acc@1: 97.66
[2025-07-10 12:15:08,008 INFO] step: 200, mrr: 98.78, Acc@1: 97.67
[2025-07-10 12:15:20,227 INFO] {'loss': 0.0181, 'grad_norm': 1.7825208902359009, 'learning_rate': 9.813278008298756e-06, 'epoch': 0.30791788856304986}
[2025-07-10 12:15:20,444 INFO] step: 210, mrr: 98.82, Acc@1: 97.74
[2025-07-10 12:15:21,082 INFO] step: 210, mrr: 98.82, Acc@1: 97.75
[2025-07-10 12:15:33,306 INFO] {'loss': 0.0136, 'grad_norm': 2.3156094551086426, 'learning_rate': 9.605809128630706e-06, 'epoch': 0.3225806451612903}
[2025-07-10 12:15:33,523 INFO] step: 220, mrr: 98.86, Acc@1: 97.82
[2025-07-10 12:15:34,157 INFO] step: 220, mrr: 98.86, Acc@1: 97.83
[2025-07-10 12:15:46,379 INFO] {'loss': 0.0256, 'grad_norm': 1.3807034492492676, 'learning_rate': 9.398340248962657e-06, 'epoch': 0.33724340175953077}
[2025-07-10 12:15:46,596 INFO] step: 230, mrr: 98.9, Acc@1: 97.9
[2025-07-10 12:15:47,234 INFO] step: 230, mrr: 98.9, Acc@1: 97.9
[2025-07-10 12:15:59,414 INFO] {'loss': 0.015, 'grad_norm': 1.5920015573501587, 'learning_rate': 9.190871369294606e-06, 'epoch': 0.3519061583577713}
[2025-07-10 12:15:59,631 INFO] step: 240, mrr: 98.93, Acc@1: 97.96
[2025-07-10 12:16:00,269 INFO] step: 240, mrr: 98.94, Acc@1: 97.97
[2025-07-10 12:16:12,460 INFO] {'loss': 0.02, 'grad_norm': 1.0597959756851196, 'learning_rate': 8.983402489626556e-06, 'epoch': 0.36656891495601174}
[2025-07-10 12:16:12,676 INFO] step: 250, mrr: 98.97, Acc@1: 98.02
[2025-07-10 12:16:13,314 INFO] step: 250, mrr: 98.97, Acc@1: 98.02
[2025-07-10 12:16:25,537 INFO] {'loss': 0.0128, 'grad_norm': 1.8561984300613403, 'learning_rate': 8.775933609958507e-06, 'epoch': 0.3812316715542522}
[2025-07-10 12:16:25,754 INFO] step: 260, mrr: 99.0, Acc@1: 98.09
[2025-07-10 12:16:26,392 INFO] step: 260, mrr: 99.0, Acc@1: 98.09
[2025-07-10 12:16:38,607 INFO] {'loss': 0.0127, 'grad_norm': 1.4424992799758911, 'learning_rate': 8.568464730290456e-06, 'epoch': 0.39589442815249265}
[2025-07-10 12:16:38,824 INFO] step: 270, mrr: 99.03, Acc@1: 98.14
[2025-07-10 12:16:39,461 INFO] step: 270, mrr: 99.03, Acc@1: 98.14
[2025-07-10 12:16:51,680 INFO] {'loss': 0.0162, 'grad_norm': 1.0608152151107788, 'learning_rate': 8.360995850622408e-06, 'epoch': 0.41055718475073316}
[2025-07-10 12:16:51,897 INFO] step: 280, mrr: 99.05, Acc@1: 98.18
[2025-07-10 12:16:52,535 INFO] step: 280, mrr: 99.05, Acc@1: 98.19
[2025-07-10 12:17:04,755 INFO] {'loss': 0.0205, 'grad_norm': 1.0031647682189941, 'learning_rate': 8.153526970954357e-06, 'epoch': 0.4252199413489736}
[2025-07-10 12:17:04,972 INFO] step: 290, mrr: 99.07, Acc@1: 98.22
[2025-07-10 12:17:05,610 INFO] step: 290, mrr: 99.07, Acc@1: 98.22
[2025-07-10 12:17:17,814 INFO] {'loss': 0.0151, 'grad_norm': 0.9890545606613159, 'learning_rate': 7.946058091286308e-06, 'epoch': 0.4398826979472141}
[2025-07-10 12:17:18,030 INFO] step: 300, mrr: 99.09, Acc@1: 98.27
[2025-07-10 12:17:18,668 INFO] step: 300, mrr: 99.1, Acc@1: 98.27
[2025-07-10 12:17:30,889 INFO] {'loss': 0.0195, 'grad_norm': 1.1821155548095703, 'learning_rate': 7.738589211618259e-06, 'epoch': 0.45454545454545453}
[2025-07-10 12:17:31,106 INFO] step: 310, mrr: 99.11, Acc@1: 98.3
[2025-07-10 12:17:31,744 INFO] step: 310, mrr: 99.11, Acc@1: 98.3
[2025-07-10 12:17:43,955 INFO] {'loss': 0.0106, 'grad_norm': 0.2908116281032562, 'learning_rate': 7.531120331950208e-06, 'epoch': 0.46920821114369504}
[2025-07-10 12:17:44,172 INFO] step: 320, mrr: 99.14, Acc@1: 98.35
[2025-07-10 12:17:44,809 INFO] step: 320, mrr: 99.14, Acc@1: 98.35
[2025-07-10 12:17:57,019 INFO] {'loss': 0.0102, 'grad_norm': 0.46281859278678894, 'learning_rate': 7.323651452282158e-06, 'epoch': 0.4838709677419355}
[2025-07-10 12:17:57,229 INFO] step: 330, mrr: 99.16, Acc@1: 98.39
[2025-07-10 12:17:57,860 INFO] step: 330, mrr: 99.16, Acc@1: 98.39
[2025-07-10 12:18:10,077 INFO] {'loss': 0.0104, 'grad_norm': 1.5589029788970947, 'learning_rate': 7.116182572614109e-06, 'epoch': 0.49853372434017595}
[2025-07-10 12:18:10,293 INFO] step: 340, mrr: 99.18, Acc@1: 98.43
[2025-07-10 12:18:10,931 INFO] step: 340, mrr: 99.18, Acc@1: 98.43
[2025-07-10 12:18:48,257 INFO] {'eval_loss': 0.0111541748046875, 'eval_mrr': 99.82599639892578, 'eval_acc1': 99.65200805664062, 'eval_runtime': 35.5621, 'eval_samples_per_second': 702.995, 'eval_steps_per_second': 2.756, 'epoch': 0.501466275659824}
[2025-07-10 12:18:48,779 INFO] Saving model checkpoint to trainer_output/checkpoint-342
[2025-07-10 12:19:03,978 INFO] {'loss': 0.0125, 'grad_norm': 3.1940810680389404, 'learning_rate': 6.9087136929460584e-06, 'epoch': 0.5131964809384164}
[2025-07-10 12:19:04,195 INFO] step: 350, mrr: 99.2, Acc@1: 98.46
[2025-07-10 12:19:04,832 INFO] step: 350, mrr: 99.2, Acc@1: 98.46
[2025-07-10 12:19:17,039 INFO] {'loss': 0.0144, 'grad_norm': 0.6890366077423096, 'learning_rate': 6.701244813278008e-06, 'epoch': 0.5278592375366569}
[2025-07-10 12:19:17,255 INFO] step: 360, mrr: 99.21, Acc@1: 98.49
[2025-07-10 12:19:17,892 INFO] step: 360, mrr: 99.21, Acc@1: 98.49
[2025-07-10 12:19:30,099 INFO] {'loss': 0.0126, 'grad_norm': 2.2104101181030273, 'learning_rate': 6.49377593360996e-06, 'epoch': 0.5425219941348973}
[2025-07-10 12:19:30,315 INFO] step: 370, mrr: 99.23, Acc@1: 98.52
[2025-07-10 12:19:30,952 INFO] step: 370, mrr: 99.23, Acc@1: 98.52
[2025-07-10 12:19:43,164 INFO] {'loss': 0.01, 'grad_norm': 0.13752619922161102, 'learning_rate': 6.2863070539419094e-06, 'epoch': 0.5571847507331378}
[2025-07-10 12:19:43,381 INFO] step: 380, mrr: 99.25, Acc@1: 98.55
[2025-07-10 12:19:44,018 INFO] step: 380, mrr: 99.25, Acc@1: 98.56
[2025-07-10 12:19:56,222 INFO] {'loss': 0.0148, 'grad_norm': 2.3461391925811768, 'learning_rate': 6.078838174273859e-06, 'epoch': 0.5718475073313783}
[2025-07-10 12:19:56,438 INFO] step: 390, mrr: 99.26, Acc@1: 98.58
[2025-07-10 12:19:57,069 INFO] step: 390, mrr: 99.26, Acc@1: 98.58
[2025-07-10 12:20:09,268 INFO] {'loss': 0.0086, 'grad_norm': 1.1968291997909546, 'learning_rate': 5.87136929460581e-06, 'epoch': 0.5865102639296188}
[2025-07-10 12:20:09,484 INFO] step: 400, mrr: 99.27, Acc@1: 98.61
[2025-07-10 12:20:10,121 INFO] step: 400, mrr: 99.27, Acc@1: 98.61
[2025-07-10 12:20:22,321 INFO] {'loss': 0.0116, 'grad_norm': 0.9763684868812561, 'learning_rate': 5.66390041493776e-06, 'epoch': 0.6011730205278593}
[2025-07-10 12:20:22,537 INFO] step: 410, mrr: 99.29, Acc@1: 98.63
[2025-07-10 12:20:23,174 INFO] step: 410, mrr: 99.29, Acc@1: 98.63
[2025-07-10 12:20:35,367 INFO] {'loss': 0.0098, 'grad_norm': 1.0943297147750854, 'learning_rate': 5.456431535269709e-06, 'epoch': 0.6158357771260997}
[2025-07-10 12:20:35,582 INFO] step: 420, mrr: 99.3, Acc@1: 98.66
[2025-07-10 12:20:36,220 INFO] step: 420, mrr: 99.3, Acc@1: 98.66
[2025-07-10 12:20:48,447 INFO] {'loss': 0.0112, 'grad_norm': 2.682663917541504, 'learning_rate': 5.24896265560166e-06, 'epoch': 0.6304985337243402}
[2025-07-10 12:20:48,664 INFO] step: 430, mrr: 99.31, Acc@1: 98.69
[2025-07-10 12:20:49,302 INFO] step: 430, mrr: 99.32, Acc@1: 98.69
[2025-07-10 12:21:01,532 INFO] {'loss': 0.0123, 'grad_norm': 0.5684580206871033, 'learning_rate': 5.041493775933611e-06, 'epoch': 0.6451612903225806}
[2025-07-10 12:21:01,748 INFO] step: 440, mrr: 99.32, Acc@1: 98.7
[2025-07-10 12:21:02,386 INFO] step: 440, mrr: 99.33, Acc@1: 98.71
[2025-07-10 12:21:14,601 INFO] {'loss': 0.0106, 'grad_norm': 0.7512679696083069, 'learning_rate': 4.83402489626556e-06, 'epoch': 0.6598240469208211}
[2025-07-10 12:21:14,817 INFO] step: 450, mrr: 99.33, Acc@1: 98.72
[2025-07-10 12:21:15,454 INFO] step: 450, mrr: 99.33, Acc@1: 98.72
[2025-07-10 12:21:27,688 INFO] {'loss': 0.0142, 'grad_norm': 1.9873898029327393, 'learning_rate': 4.626556016597511e-06, 'epoch': 0.6744868035190615}
[2025-07-10 12:21:27,904 INFO] step: 460, mrr: 99.34, Acc@1: 98.74
[2025-07-10 12:21:28,542 INFO] step: 460, mrr: 99.35, Acc@1: 98.74
[2025-07-10 12:21:40,777 INFO] {'loss': 0.0145, 'grad_norm': 2.0032401084899902, 'learning_rate': 4.419087136929461e-06, 'epoch': 0.6891495601173021}
[2025-07-10 12:21:40,993 INFO] step: 470, mrr: 99.35, Acc@1: 98.76
[2025-07-10 12:21:41,631 INFO] step: 470, mrr: 99.35, Acc@1: 98.76
[2025-07-10 12:21:53,852 INFO] {'loss': 0.0089, 'grad_norm': 1.3466904163360596, 'learning_rate': 4.211618257261411e-06, 'epoch': 0.7038123167155426}
[2025-07-10 12:21:54,068 INFO] step: 480, mrr: 99.36, Acc@1: 98.78
[2025-07-10 12:21:54,706 INFO] step: 480, mrr: 99.36, Acc@1: 98.78
[2025-07-10 12:22:06,934 INFO] {'loss': 0.0103, 'grad_norm': 2.052752733230591, 'learning_rate': 4.004149377593361e-06, 'epoch': 0.718475073313783}
[2025-07-10 12:22:07,150 INFO] step: 490, mrr: 99.37, Acc@1: 98.8
[2025-07-10 12:22:07,788 INFO] step: 490, mrr: 99.37, Acc@1: 98.8
[2025-07-10 12:22:20,018 INFO] {'loss': 0.008, 'grad_norm': 0.7489900588989258, 'learning_rate': 3.7966804979253114e-06, 'epoch': 0.7331378299120235}
[2025-07-10 12:22:20,234 INFO] step: 500, mrr: 99.38, Acc@1: 98.82
[2025-07-10 12:22:20,872 INFO] step: 500, mrr: 99.38, Acc@1: 98.82
[2025-07-10 12:22:33,106 INFO] {'loss': 0.0105, 'grad_norm': 0.3516148030757904, 'learning_rate': 3.5892116182572616e-06, 'epoch': 0.7478005865102639}
[2025-07-10 12:22:33,323 INFO] step: 510, mrr: 99.39, Acc@1: 98.83
[2025-07-10 12:22:33,958 INFO] step: 510, mrr: 99.39, Acc@1: 98.83
[2025-07-10 12:23:12,576 INFO] {'eval_loss': 0.00981903076171875, 'eval_mrr': 99.8479995727539, 'eval_acc1': 99.69600677490234, 'eval_runtime': 35.5507, 'eval_samples_per_second': 703.221, 'eval_steps_per_second': 2.757, 'epoch': 0.7521994134897361}
[2025-07-10 12:23:13,109 INFO] Saving model checkpoint to trainer_output/checkpoint-513
[2025-07-10 12:23:26,932 INFO] {'loss': 0.0122, 'grad_norm': 1.5468149185180664, 'learning_rate': 3.381742738589212e-06, 'epoch': 0.7624633431085044}
[2025-07-10 12:23:27,148 INFO] step: 520, mrr: 99.4, Acc@1: 98.85
[2025-07-10 12:23:27,786 INFO] step: 520, mrr: 99.4, Acc@1: 98.85
[2025-07-10 12:23:39,996 INFO] {'loss': 0.0125, 'grad_norm': 2.38387131690979, 'learning_rate': 3.174273858921162e-06, 'epoch': 0.7771260997067448}
[2025-07-10 12:23:40,212 INFO] step: 530, mrr: 99.41, Acc@1: 98.86
[2025-07-10 12:23:40,849 INFO] step: 530, mrr: 99.41, Acc@1: 98.86
[2025-07-10 12:23:53,075 INFO] {'loss': 0.0115, 'grad_norm': 0.33783435821533203, 'learning_rate': 2.966804979253112e-06, 'epoch': 0.7917888563049853}
[2025-07-10 12:23:53,291 INFO] step: 540, mrr: 99.42, Acc@1: 98.88
[2025-07-10 12:23:53,928 INFO] step: 540, mrr: 99.42, Acc@1: 98.88
[2025-07-10 12:24:06,131 INFO] {'loss': 0.0084, 'grad_norm': 1.1909300088882446, 'learning_rate': 2.7593360995850628e-06, 'epoch': 0.8064516129032258}
[2025-07-10 12:24:06,347 INFO] step: 550, mrr: 99.42, Acc@1: 98.89
[2025-07-10 12:24:06,984 INFO] step: 550, mrr: 99.42, Acc@1: 98.89
[2025-07-10 12:24:19,187 INFO] {'loss': 0.009, 'grad_norm': 1.7507719993591309, 'learning_rate': 2.5518672199170125e-06, 'epoch': 0.8211143695014663}
[2025-07-10 12:24:19,403 INFO] step: 560, mrr: 99.43, Acc@1: 98.91
[2025-07-10 12:24:20,040 INFO] step: 560, mrr: 99.43, Acc@1: 98.91
[2025-07-10 12:24:32,233 INFO] {'loss': 0.0044, 'grad_norm': 1.077887773513794, 'learning_rate': 2.3443983402489627e-06, 'epoch': 0.8357771260997068}
[2025-07-10 12:24:32,449 INFO] step: 570, mrr: 99.44, Acc@1: 98.92
[2025-07-10 12:24:33,085 INFO] step: 570, mrr: 99.44, Acc@1: 98.92
[2025-07-10 12:24:45,277 INFO] {'loss': 0.0078, 'grad_norm': 0.7550936341285706, 'learning_rate': 2.136929460580913e-06, 'epoch': 0.8504398826979472}
[2025-07-10 12:24:45,492 INFO] step: 580, mrr: 99.45, Acc@1: 98.94
[2025-07-10 12:24:46,129 INFO] step: 580, mrr: 99.45, Acc@1: 98.94
[2025-07-10 12:24:58,319 INFO] {'loss': 0.0089, 'grad_norm': 1.298823595046997, 'learning_rate': 1.929460580912863e-06, 'epoch': 0.8651026392961877}
[2025-07-10 12:24:58,534 INFO] step: 590, mrr: 99.46, Acc@1: 98.95
[2025-07-10 12:24:59,171 INFO] step: 590, mrr: 99.46, Acc@1: 98.95
[2025-07-10 12:25:11,368 INFO] {'loss': 0.0121, 'grad_norm': 0.5326959490776062, 'learning_rate': 1.7219917012448133e-06, 'epoch': 0.8797653958944281}
[2025-07-10 12:25:11,584 INFO] step: 600, mrr: 99.46, Acc@1: 98.97
[2025-07-10 12:25:12,221 INFO] step: 600, mrr: 99.46, Acc@1: 98.97
[2025-07-10 12:25:24,420 INFO] {'loss': 0.0146, 'grad_norm': 0.4671313166618347, 'learning_rate': 1.5145228215767635e-06, 'epoch': 0.8944281524926686}
[2025-07-10 12:25:24,635 INFO] step: 610, mrr: 99.47, Acc@1: 98.97
[2025-07-10 12:25:25,271 INFO] step: 610, mrr: 99.47, Acc@1: 98.97
[2025-07-10 12:25:37,467 INFO] {'loss': 0.0131, 'grad_norm': 1.9670019149780273, 'learning_rate': 1.307053941908714e-06, 'epoch': 0.9090909090909091}
[2025-07-10 12:25:37,683 INFO] step: 620, mrr: 99.47, Acc@1: 98.98
[2025-07-10 12:25:38,319 INFO] step: 620, mrr: 99.47, Acc@1: 98.98
[2025-07-10 12:25:50,484 INFO] {'loss': 0.0137, 'grad_norm': 1.0361846685409546, 'learning_rate': 1.099585062240664e-06, 'epoch': 0.9237536656891495}
[2025-07-10 12:25:50,698 INFO] step: 630, mrr: 99.48, Acc@1: 98.99
[2025-07-10 12:25:51,332 INFO] step: 630, mrr: 99.48, Acc@1: 98.99
[2025-07-10 12:26:03,521 INFO] {'loss': 0.0122, 'grad_norm': 1.590194582939148, 'learning_rate': 8.921161825726142e-07, 'epoch': 0.9384164222873901}
[2025-07-10 12:26:03,737 INFO] step: 640, mrr: 99.48, Acc@1: 99.0
[2025-07-10 12:26:04,374 INFO] step: 640, mrr: 99.48, Acc@1: 99.0
[2025-07-10 12:26:16,574 INFO] {'loss': 0.0109, 'grad_norm': 1.287424087524414, 'learning_rate': 6.846473029045644e-07, 'epoch': 0.9530791788856305}
[2025-07-10 12:26:16,790 INFO] step: 650, mrr: 99.49, Acc@1: 99.01
[2025-07-10 12:26:17,425 INFO] step: 650, mrr: 99.49, Acc@1: 99.01
[2025-07-10 12:26:29,618 INFO] {'loss': 0.009, 'grad_norm': 0.2547227144241333, 'learning_rate': 4.771784232365145e-07, 'epoch': 0.967741935483871}
[2025-07-10 12:26:29,834 INFO] step: 660, mrr: 99.49, Acc@1: 99.02
[2025-07-10 12:26:30,470 INFO] step: 660, mrr: 99.49, Acc@1: 99.02
[2025-07-10 12:26:42,668 INFO] {'loss': 0.0103, 'grad_norm': 1.8279532194137573, 'learning_rate': 2.6970954356846476e-07, 'epoch': 0.9824046920821115}
[2025-07-10 12:26:42,883 INFO] step: 670, mrr: 99.5, Acc@1: 99.03
[2025-07-10 12:26:43,520 INFO] step: 670, mrr: 99.5, Acc@1: 99.03
[2025-07-10 12:26:55,707 INFO] {'loss': 0.0088, 'grad_norm': 1.043994665145874, 'learning_rate': 6.224066390041494e-08, 'epoch': 0.9970674486803519}
[2025-07-10 12:26:55,922 INFO] step: 680, mrr: 99.5, Acc@1: 99.04
[2025-07-10 12:26:56,558 INFO] step: 680, mrr: 99.5, Acc@1: 99.04
[2025-07-10 12:26:58,452 INFO] Saving model checkpoint to trainer_output/checkpoint-682
[2025-07-10 12:27:03,177 INFO] {'train_runtime': 1049.7754, 'train_samples_per_second': 166.199, 'train_steps_per_second': 0.65, 'train_loss': 0.029093579725086513, 'epoch': 1.0}
[2025-07-10 12:28:06,824 INFO] Saving model checkpoint to trainer_output
[2025-07-10 12:28:08,258 INFO] Saving model checkpoint to trainer_output
